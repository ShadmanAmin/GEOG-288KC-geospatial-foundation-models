---
title: "Week 2: Rapid Remote Sensing Preprocessing"
subtitle: "Building efficient pipelines for Sentinel-2 preprocessing"
jupyter: geoai
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: false
---

## Introduction

This week we'll build production-ready preprocessing pipelines that can handle multiple Sentinel-2 scenes efficiently. You'll learn to process entire datasets, not just single scenes, with cloud masking, reprojection, and mosaicking.

:::{.callout-tip}
## Learning Goals
By the end of this session, you will:
- Build reproducible preprocessing pipelines for multiple scenes
- Handle cloud masking using Sentinel-2's Scene Classification Layer
- Reproject and mosaic multiple satellite scenes
- Create analysis-ready data cubes with xarray
- Optimize workflows with dask for large datasets
:::

## Session Overview

Today's hands-on workflow:

| Step | Activity | Tools | Output |
|------|----------|-------|--------|
| 1 | Multi-scene data discovery | pystac-client | Scene inventory |
| 2 | Cloud masking pipeline | rasterio, numpy | Clean pixels only |
| 3 | Reprojection & mosaicking | rasterio, rioxarray | Unified grid |
| 4 | Analysis-ready data cubes | xarray, dask | Time series ready data |
| 5 | Batch processing workflow | pathlib, concurrent.futures | Scalable pipeline |

---

## Step 1: Multi-Scene Data Discovery

Let's scale up from Week 1's single scene approach to handle multiple scenes across time and space.

### Define Study Area and Time Range

```{python}
import warnings
warnings.filterwarnings('ignore')

# Core libraries
import numpy as np
import pandas as pd
import xarray as xr
import rasterio
from rasterio.warp import calculate_default_transform, reproject, Resampling
from rasterio.merge import merge
import rioxarray
from pathlib import Path
from datetime import datetime, timedelta
from pystac_client import Client
import folium
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor
import dask
from dask.distributed import Client as DaskClient

# Set up study area - Central Valley, California (agriculture focus)
central_valley_bbox = [-121.5, 36.5, -120.0, 38.0]  # [west, south, east, north]

# Define longer time range for trend analysis
start_date = "2024-06-01"
end_date = "2024-09-01"
max_cloud_cover = 15  # More restrictive for cleaner mosaics

print(f"üó∫Ô∏è Study Area: Central Valley, California")
print(f"üìÖ Time Range: {start_date} to {end_date}")
print(f"‚òÅÔ∏è Max Cloud Cover: {max_cloud_cover}%")
```

### Search for Multiple Scenes

```{python}
# Connect to Microsoft Planetary Computer
catalog = Client.open("https://planetarycomputer.microsoft.com/api/stac/v1")

# Enhanced search parameters for multiple scenes
search_params = {
    "collections": ["sentinel-2-l2a"],
    "bbox": central_valley_bbox,
    "datetime": f"{start_date}/{end_date}",
    "query": {
        "eo:cloud_cover": {"lt": max_cloud_cover}
    },
    "limit": 50  # Get more scenes for time series
}

print("üîç Searching for multiple Sentinel-2 scenes...")
search_results = catalog.search(**search_params)
items = list(search_results.items())

print(f"üì∏ Found {len(items)} scenes")

# Organize scenes by date and tile
scene_info = []
for item in items:
    props = item.properties
    date = props['datetime'].split('T')[0]
    tile_id = item.id.split('_')[5]  # Extract tile ID from scene name
    cloud_cover = props.get('eo:cloud_cover', 0)

    scene_info.append({
        'id': item.id,
        'date': date,
        'tile': tile_id,
        'cloud_cover': cloud_cover,
        'item': item
    })

# Convert to DataFrame for easier analysis
scenes_df = pd.DataFrame(scene_info)
print(f"\nüìä Scene Distribution:")
print(f"   Unique dates: {scenes_df['date'].nunique()}")
print(f"   Unique tiles: {scenes_df['tile'].nunique()}")
print(f"   Date range: {scenes_df['date'].min()} to {scenes_df['date'].max()}")

# Show scenes by tile
print(f"\nüóÇÔ∏è Scenes by Tile:")
tile_counts = scenes_df.groupby('tile').size().sort_values(ascending=False)
for tile, count in tile_counts.head().items():
    avg_cloud = scenes_df[scenes_df['tile'] == tile]['cloud_cover'].mean()
    print(f"   {tile}: {count} scenes (avg cloud: {avg_cloud:.1f}%)")
```

### Visualize Scene Coverage

```{python}
# Create map showing all scene footprints
m = folium.Map(
    location=[37.25, -120.75],  # Center of Central Valley
    zoom_start=8,
    tiles='OpenStreetMap'
)

# Add study area boundary
folium.Rectangle(
    bounds=[[central_valley_bbox[1], central_valley_bbox[0]],
            [central_valley_bbox[3], central_valley_bbox[2]]],
    color='red',
    fill=False,
    weight=3,
    popup="Study Area: Central Valley"
).add_to(m)

# Add scene footprints colored by date
colors = ['blue', 'green', 'orange', 'purple', 'red']
unique_dates = sorted(scenes_df['date'].unique())

for i, date in enumerate(unique_dates[:5]):  # Show first 5 dates
    date_scenes = scenes_df[scenes_df['date'] == date]
    color = colors[i % len(colors)]

    for _, scene in date_scenes.iterrows():
        item = scene['item']
        geom = item.geometry

        # Add scene footprint
        folium.GeoJson(
            geom,
            style_function=lambda x, color=color: {
                'fillColor': color,
                'color': color,
                'weight': 2,
                'fillOpacity': 0.3
            },
            popup=f"Date: {date}<br>Tile: {scene['tile']}<br>Cloud: {scene['cloud_cover']:.1f}%"
        ).add_to(m)

folium.LayerControl().add_to(m)
print("üó∫Ô∏è Scene coverage map created")
m
```

---

## Step 2: Cloud Masking Pipeline

Sentinel-2 Level 2A includes a Scene Classification Layer (SCL) that identifies clouds, cloud shadows, and other features.

### Understanding Scene Classification Layer

```{python}
# SCL class definitions (Sentinel-2 Level 2A)
scl_classes = {
    0: "No Data",
    1: "Saturated or defective",
    2: "Dark area pixels",
    3: "Cloud shadows",
    4: "Vegetation",
    5: "Not vegetated",
    6: "Water",
    7: "Unclassified",
    8: "Cloud medium probability",
    9: "Cloud high probability",
    10: "Thin cirrus",
    11: "Snow"
}

# Define what we consider "good" pixels for analysis
good_pixel_classes = [4, 5, 6]  # Vegetation, not vegetated, water
cloud_classes = [3, 8, 9, 10]   # Cloud shadows, clouds, cirrus

print("üå•Ô∏è Scene Classification Layer (SCL) Classes:")
for class_id, description in scl_classes.items():
    marker = "‚úì" if class_id in good_pixel_classes else "‚ùå" if class_id in cloud_classes else "‚ö†Ô∏è"
    print(f"   {marker} {class_id}: {description}")

print(f"\n‚úÖ Good pixels for analysis: {good_pixel_classes}")
print(f"‚òÅÔ∏è Cloud/shadow pixels to mask: {cloud_classes}")
```

### Load Scene with Cloud Mask

```{python}
def load_scene_with_cloudmask(item, target_crs='EPSG:32610', target_resolution=20):
    """
    Load a Sentinel-2 scene with cloud masking applied.

    Args:
        item: STAC item
        target_crs: Target coordinate reference system
        target_resolution: Target pixel size in meters

    Returns:
        masked_data: dict with masked bands
        valid_pixel_fraction: fraction of valid pixels
    """
    try:
        # Load key bands and SCL
        bands_to_load = {
            'B04': 'red',     # 10m resolution
            'B03': 'green',   # 10m resolution
            'B02': 'blue',    # 10m resolution
            'B08': 'nir',     # 10m resolution
            'SCL': 'scl'      # 20m resolution
        }

        loaded_data = {}

        # Load each band
        for band_key, band_name in bands_to_load.items():
            url = item.assets[band_key].href

            # Load with rioxarray for automatic CRS handling
            da = rioxarray.open_rasterio(url).squeeze()

            # Reproject to target CRS and resolution if needed
            if da.rio.crs != target_crs or abs(da.rio.resolution()[0]) != target_resolution:
                da = da.rio.reproject(target_crs, resolution=target_resolution)

            loaded_data[band_name] = da

        # Create cloud mask from SCL
        scl_data = loaded_data['scl']
        good_pixels = np.isin(scl_data.values, good_pixel_classes)

        # Apply mask to all spectral bands
        masked_data = {}
        for band_name in ['red', 'green', 'blue', 'nir']:
            band_data = loaded_data[band_name]
            # Mask invalid pixels with NaN
            masked_values = np.where(good_pixels, band_data.values, np.nan)

            # Create new DataArray with same coordinates
            masked_data[band_name] = xr.DataArray(
                masked_values,
                coords=band_data.coords,
                dims=band_data.dims,
                attrs=band_data.attrs
            )

        # Calculate valid pixel fraction
        valid_pixel_fraction = np.sum(good_pixels) / good_pixels.size

        # Store SCL for reference
        masked_data['scl'] = scl_data
        masked_data['cloud_mask'] = xr.DataArray(
            good_pixels,
            coords=scl_data.coords,
            dims=scl_data.dims
        )

        return masked_data, valid_pixel_fraction

    except Exception as e:
        print(f"‚ùå Error loading scene {item.id}: {e}")
        return None, 0

# Test with one scene
test_item = scenes_df.iloc[0]['item']
print(f"üß™ Testing cloud masking with scene: {test_item.id}")

masked_data, valid_fraction = load_scene_with_cloudmask(test_item)

if masked_data:
    print(f"‚úÖ Scene loaded successfully")
    print(f"üìè Data shape: {masked_data['red'].shape}")
    print(f"üó∫Ô∏è CRS: {masked_data['red'].rio.crs}")
    print(f"üìä Valid pixels: {valid_fraction:.1%}")
    print(f"‚òÅÔ∏è Cloudy pixels: {1-valid_fraction:.1%}")
else:
    print("‚ùå Failed to load scene")
```

### Visualize Cloud Masking Results

```{python}
if masked_data:
    # Create visualization of cloud masking
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))

    # Original RGB (before masking)
    red_orig = masked_data['red'].fillna(0)  # Fill NaN for display
    green_orig = masked_data['green'].fillna(0)
    blue_orig = masked_data['blue'].fillna(0)

    # Normalize for RGB display
    def normalize_for_display(band, percentiles=(2, 98)):
        valid_data = band[~np.isnan(band)]
        if len(valid_data) > 0:
            p_low, p_high = np.percentile(valid_data, percentiles)
            return np.clip((band - p_low) / (p_high - p_low), 0, 1)
        return band

    red_norm = normalize_for_display(red_orig.values)
    green_norm = normalize_for_display(green_orig.values)
    blue_norm = normalize_for_display(blue_orig.values)

    rgb_composite = np.dstack([red_norm, green_norm, blue_norm])

    # Plot results
    axes[0,0].imshow(rgb_composite)
    axes[0,0].set_title('RGB Composite')
    axes[0,0].axis('off')

    # Scene Classification Layer
    scl_plot = axes[0,1].imshow(masked_data['scl'].values, cmap='tab20', vmin=0, vmax=11)
    axes[0,1].set_title('Scene Classification Layer')
    axes[0,1].axis('off')

    # Cloud mask
    axes[0,2].imshow(masked_data['cloud_mask'].values, cmap='RdYlGn', vmin=0, vmax=1)
    axes[0,2].set_title('Valid Pixels Mask')
    axes[0,2].axis('off')

    # Masked RGB
    masked_rgb = rgb_composite.copy()
    masked_rgb[~masked_data['cloud_mask'].values] = [1, 0, 0]  # Red for masked areas
    axes[1,0].imshow(masked_rgb)
    axes[1,0].set_title('Masked RGB (Red = Clouds)')
    axes[1,0].axis('off')

    # NDVI calculation on masked data
    nir_masked = masked_data['nir'].values
    red_masked = masked_data['red'].values
    ndvi = (nir_masked - red_masked) / (nir_masked + red_masked + 1e-8)

    ndvi_plot = axes[1,1].imshow(ndvi, cmap='RdYlGn', vmin=-0.5, vmax=1.0)
    axes[1,1].set_title('NDVI (Clouds Excluded)')
    axes[1,1].axis('off')
    plt.colorbar(ndvi_plot, ax=axes[1,1], shrink=0.6)

    # Statistics
    axes[1,2].text(0.1, 0.8, f"Valid Pixels: {valid_fraction:.1%}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.6, f"Cloudy Pixels: {1-valid_fraction:.1%}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.4, f"NDVI Range: {np.nanmin(ndvi):.2f} to {np.nanmax(ndvi):.2f}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].text(0.1, 0.2, f"Mean NDVI: {np.nanmean(ndvi):.2f}", transform=axes[1,2].transAxes, fontsize=12)
    axes[1,2].set_title('Statistics')
    axes[1,2].axis('off')

    plt.tight_layout()
    plt.show()

    print("üé® Cloud masking visualization complete")
```

:::{.callout-note}
## Scene Classification Layer Benefits
- **Automated cloud detection**: No manual threshold setting needed
- **Multiple cloud types**: Distinguishes dense clouds, thin cirrus, and shadows
- **Consistent classification**: Same algorithm across all Sentinel-2 scenes
- **Analysis-ready**: Level 2A processing includes atmospheric correction
:::

---

## Step 3: Reprojection and Mosaicking

When working with multiple scenes, we need to ensure they're all in the same coordinate system and can be combined seamlessly.

### Batch Process Multiple Scenes

```{python}
def process_scene_batch(scene_items, max_workers=4, target_crs='EPSG:32610'):
    """
    Process multiple scenes in parallel with cloud masking and reprojection.

    Args:
        scene_items: List of STAC items
        max_workers: Number of parallel workers
        target_crs: Target coordinate reference system

    Returns:
        processed_scenes: List of processed scene data
    """
    processed_scenes = []

    def process_single_scene(item):
        print(f"Processing {item.id[:50]}...")
        data, valid_frac = load_scene_with_cloudmask(item, target_crs=target_crs)
        if data and valid_frac > 0.3:  # Keep scenes with >30% valid pixels
            return {
                'id': item.id,
                'date': item.properties['datetime'].split('T')[0],
                'data': data,
                'valid_fraction': valid_frac,
                'item': item
            }
        return None

    # Process scenes in parallel
    print(f"üîÑ Processing {len(scene_items)} scenes with {max_workers} workers...")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(process_single_scene, scene_items))

    # Filter successful results
    processed_scenes = [result for result in results if result is not None]

    print(f"‚úÖ Successfully processed {len(processed_scenes)} scenes")
    return processed_scenes

# Select subset of scenes for processing (to manage computational load)
selected_scenes = scenes_df.head(8)['item'].tolist()  # Process first 8 scenes
processed_scenes = process_scene_batch(selected_scenes, max_workers=2)

# Show processing results
if processed_scenes:
    print(f"\nüìä Processing Summary:")
    for scene in processed_scenes:
        print(f"   {scene['date']}: {scene['valid_fraction']:.1%} valid pixels")
```

### Create Temporal Mosaic

```{python}
def create_temporal_mosaic(processed_scenes, method='median'):
    """
    Create a temporal mosaic from multiple processed scenes.

    Args:
        processed_scenes: List of processed scene dictionaries
        method: Compositing method ('median', 'mean', 'max')

    Returns:
        mosaic_data: Temporal composite as xarray Dataset
    """
    if not processed_scenes:
        print("‚ùå No scenes to mosaic")
        return None

    print(f"üß© Creating temporal mosaic using {method} method...")

    # Group data by band
    bands = ['red', 'green', 'blue', 'nir']
    band_stacks = {}
    dates = []

    for band in bands:
        band_data = []
        for scene in processed_scenes:
            band_data.append(scene['data'][band])
            if band == 'red':  # Only collect dates once
                dates.append(scene['date'])

        # Stack along time dimension
        band_stack = xr.concat(band_data, dim='time')
        band_stack = band_stack.assign_coords(time=dates)

        # Apply temporal compositing
        if method == 'median':
            band_stacks[band] = band_stack.median(dim='time', skipna=True)
        elif method == 'mean':
            band_stacks[band] = band_stack.mean(dim='time', skipna=True)
        elif method == 'max':
            band_stacks[band] = band_stack.max(dim='time', skipna=True)

    # Create mosaic dataset
    mosaic_data = xr.Dataset(band_stacks)

    # Add metadata
    mosaic_data.attrs['method'] = method
    mosaic_data.attrs['n_scenes'] = len(processed_scenes)
    mosaic_data.attrs['date_range'] = f"{min(dates)} to {max(dates)}"

    print(f"‚úÖ Mosaic created from {len(processed_scenes)} scenes")
    print(f"üìè Mosaic shape: {mosaic_data['red'].shape}")
    print(f"üìÖ Date range: {mosaic_data.attrs['date_range']}")

    return mosaic_data

# Create median composite
mosaic = create_temporal_mosaic(processed_scenes, method='median')

if mosaic:
    # Visualize the mosaic
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))

    # RGB composite of mosaic
    red_norm = normalize_for_display(mosaic['red'].values)
    green_norm = normalize_for_display(mosaic['green'].values)
    blue_norm = normalize_for_display(mosaic['blue'].values)
    rgb_mosaic = np.dstack([red_norm, green_norm, blue_norm])

    axes[0].imshow(rgb_mosaic)
    axes[0].set_title(f'RGB Mosaic ({mosaic.attrs["method"]})')
    axes[0].axis('off')

    # NDVI mosaic
    nir_vals = mosaic['nir'].values
    red_vals = mosaic['red'].values
    ndvi_mosaic = (nir_vals - red_vals) / (nir_vals + red_vals + 1e-8)

    ndvi_plot = axes[1].imshow(ndvi_mosaic, cmap='RdYlGn', vmin=-0.2, vmax=0.8)
    axes[1].set_title('NDVI Mosaic')
    axes[1].axis('off')
    plt.colorbar(ndvi_plot, ax=axes[1], shrink=0.8)

    # Data availability (how many scenes contributed to each pixel)
    # This would require tracking per-pixel contributions
    axes[2].text(0.1, 0.5, f"Scenes used: {mosaic.attrs['n_scenes']}\n"
                           f"Method: {mosaic.attrs['method']}\n"
                           f"Date range: {mosaic.attrs['date_range']}\n"
                           f"Coverage: Central Valley, CA",
                transform=axes[2].transAxes, fontsize=12, verticalalignment='center')
    axes[2].set_title('Mosaic Info')
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

    print("üé® Temporal mosaic visualization complete")
```

---

## Step 4: Analysis-Ready Data Cubes

Now let's create analysis-ready data cubes that can be used for time series analysis and machine learning.

### Build Temporal Data Cube

```{python}
def build_temporal_datacube(processed_scenes, chunk_size='auto'):
    """
    Build an analysis-ready temporal data cube.

    Args:
        processed_scenes: List of processed scenes
        chunk_size: Dask chunk size for memory management

    Returns:
        datacube: xarray Dataset with time dimension
    """
    if not processed_scenes:
        return None

    print("üìä Building temporal data cube...")

    # Sort scenes by date
    processed_scenes.sort(key=lambda x: x['date'])

    # Extract dates and data
    dates = [pd.to_datetime(scene['date']) for scene in processed_scenes]
    bands = ['red', 'green', 'blue', 'nir']

    # Build data arrays for each band
    band_cubes = {}

    for band in bands:
        # Stack all scenes for this band
        band_data = []
        for scene in processed_scenes:
            band_data.append(scene['data'][band])

        # Create temporal stack
        band_cube = xr.concat(band_data, dim='time')
        band_cube = band_cube.assign_coords(time=dates)

        # Add chunking for large datasets
        if chunk_size == 'auto':
            chunks = {'time': 1, 'y': 512, 'x': 512}
        else:
            chunks = chunk_size

        band_cubes[band] = band_cube.chunk(chunks)

    # Create dataset
    datacube = xr.Dataset(band_cubes)

    # Add derived indices
    print("üßÆ Computing vegetation indices...")
    datacube['ndvi'] = ((datacube['nir'] - datacube['red']) /
                        (datacube['nir'] + datacube['red'] + 1e-8))

    # Enhanced Vegetation Index (EVI)
    datacube['evi'] = (2.5 * (datacube['nir'] - datacube['red']) /
                       (datacube['nir'] + 6 * datacube['red'] - 7.5 * datacube['blue'] + 1))

    # Add metadata
    datacube.attrs.update({
        'title': 'Sentinel-2 Analysis-Ready Data Cube',
        'description': 'Cloud-masked, reprojected temporal stack',
        'n_scenes': len(processed_scenes),
        'time_range': f"{dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}",
        'crs': str(datacube['red'].rio.crs),
        'resolution': datacube['red'].rio.resolution()
    })

    print(f"‚úÖ Data cube created:")
    print(f"   Shape: {datacube['red'].shape}")
    print(f"   Time steps: {len(dates)}")
    print(f"   Variables: {list(datacube.data_vars)}")

    return datacube

# Build the data cube
datacube = build_temporal_datacube(processed_scenes)

if datacube:
    print(f"\nüì¶ Data Cube Summary:")
    print(datacube)
```

### Time Series Analysis Example

```{python}
if datacube:
    # Extract time series for a sample location
    # Pick center of study area
    center_y, center_x = datacube.y.values[len(datacube.y)//2], datacube.x.values[len(datacube.x)//2]

    # Extract time series at center point
    point_ts = datacube.sel(x=center_x, y=center_y, method='nearest')

    # Create time series plots
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))

    # NDVI time series
    axes[0,0].plot(point_ts.time, point_ts['ndvi'], 'g-o', markersize=4)
    axes[0,0].set_title('NDVI Time Series')
    axes[0,0].set_ylabel('NDVI')
    axes[0,0].grid(True, alpha=0.3)

    # EVI time series
    axes[0,1].plot(point_ts.time, point_ts['evi'], 'b-o', markersize=4)
    axes[0,1].set_title('EVI Time Series')
    axes[0,1].set_ylabel('EVI')
    axes[0,1].grid(True, alpha=0.3)

    # RGB bands time series
    axes[1,0].plot(point_ts.time, point_ts['red'], 'r-', label='Red', alpha=0.7)
    axes[1,0].plot(point_ts.time, point_ts['green'], 'g-', label='Green', alpha=0.7)
    axes[1,0].plot(point_ts.time, point_ts['blue'], 'b-', label='Blue', alpha=0.7)
    axes[1,0].set_title('RGB Bands Time Series')
    axes[1,0].set_ylabel('Reflectance')
    axes[1,0].legend()
    axes[1,0].grid(True, alpha=0.3)

    # NIR time series
    axes[1,1].plot(point_ts.time, point_ts['nir'], 'darkred', marker='o', markersize=4)
    axes[1,1].set_title('NIR Band Time Series')
    axes[1,1].set_ylabel('NIR Reflectance')
    axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    print("üìà Time series analysis complete")
    print(f"Sample location: x={center_x:.0f}, y={center_y:.0f}")
```

---

## Step 5: Scalable Batch Processing Workflow

Finally, let's create a reproducible workflow that can handle larger datasets efficiently.

### Create Preprocessing Pipeline Class

```{python}
class Sentinel2Preprocessor:
    """
    Scalable Sentinel-2 preprocessing pipeline.
    """

    def __init__(self, output_dir="preprocessed_data", target_crs='EPSG:32610',
                 target_resolution=20, max_cloud_cover=15):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.target_crs = target_crs
        self.target_resolution = target_resolution
        self.max_cloud_cover = max_cloud_cover

        print(f"üîß Preprocessing pipeline initialized")
        print(f"   Output directory: {self.output_dir}")
        print(f"   Target CRS: {self.target_crs}")
        print(f"   Target resolution: {self.target_resolution}m")

    def search_scenes(self, bbox, start_date, end_date, limit=100):
        """Search for Sentinel-2 scenes."""
        catalog = Client.open("https://planetarycomputer.microsoft.com/api/stac/v1")

        search_params = {
            "collections": ["sentinel-2-l2a"],
            "bbox": bbox,
            "datetime": f"{start_date}/{end_date}",
            "query": {"eo:cloud_cover": {"lt": self.max_cloud_cover}},
            "limit": limit
        }

        search_results = catalog.search(**search_params)
        items = list(search_results.items())

        print(f"üîç Found {len(items)} scenes")
        return items

    def process_scene(self, item, save_individual=True):
        """Process a single scene with cloud masking."""
        scene_id = item.id
        output_path = self.output_dir / f"{scene_id}_processed.nc"

        # Skip if already processed
        if output_path.exists():
            print(f"‚è≠Ô∏è Skipping {scene_id} (already processed)")
            return str(output_path)

        # Process scene
        data, valid_frac = load_scene_with_cloudmask(
            item, self.target_crs, self.target_resolution
        )

        if data and valid_frac > 0.3:
            if save_individual:
                # Convert to xarray Dataset
                scene_ds = xr.Dataset(data)
                scene_ds.attrs.update({
                    'scene_id': scene_id,
                    'date': item.properties['datetime'].split('T')[0],
                    'cloud_cover': item.properties.get('eo:cloud_cover', 0),
                    'valid_pixel_fraction': valid_frac
                })

                # Save to NetCDF
                scene_ds.to_netcdf(output_path, engine='netcdf4')
                print(f"üíæ Saved: {output_path.name}")

            return data
        else:
            print(f"‚ùå Skipped {scene_id} (insufficient valid pixels)")
            return None

    def create_time_series_cube(self, processed_data_list, cube_name="datacube"):
        """Create and save temporal data cube."""
        if not processed_data_list:
            print("‚ùå No data to create cube")
            return None

        cube_path = self.output_dir / f"{cube_name}.nc"

        # Build temporal stack
        dates = []
        band_stacks = {band: [] for band in ['red', 'green', 'blue', 'nir']}

        for data in processed_data_list:
            if data:
                for band in band_stacks.keys():
                    band_stacks[band].append(data[band])

        # Create dataset
        cube_data = {}
        for band, stack in band_stacks.items():
            if stack:
                cube_data[band] = xr.concat(stack, dim='time')

        if cube_data:
            datacube = xr.Dataset(cube_data)

            # Add vegetation indices
            datacube['ndvi'] = ((datacube['nir'] - datacube['red']) /
                               (datacube['nir'] + datacube['red'] + 1e-8))

            # Save cube
            datacube.to_netcdf(cube_path, engine='netcdf4')
            print(f"üì¶ Data cube saved: {cube_path}")

            return datacube

        return None

# Initialize preprocessor
preprocessor = Sentinel2Preprocessor(
    output_dir="week2_preprocessed",
    target_crs='EPSG:32610',  # UTM Zone 10N for California
    target_resolution=20
)

print("‚úÖ Preprocessing pipeline ready")
```

### Run Complete Preprocessing Workflow

```{python}
# Define workflow parameters
workflow_params = {
    'bbox': central_valley_bbox,
    'start_date': "2024-07-01",
    'end_date': "2024-08-15",
    'max_scenes': 10  # Limit for demonstration
}

print(f"üöÄ Starting complete preprocessing workflow...")
print(f"   Area: Central Valley, CA")
print(f"   Period: {workflow_params['start_date']} to {workflow_params['end_date']}")

# Step 1: Search for scenes
workflow_items = preprocessor.search_scenes(
    workflow_params['bbox'],
    workflow_params['start_date'],
    workflow_params['end_date'],
    limit=workflow_params['max_scenes']
)

# Step 2: Process scenes
processed_data = []
for i, item in enumerate(workflow_items[:5]):  # Process first 5 for demo
    print(f"Processing scene {i+1}/{min(5, len(workflow_items))}: {item.id[:50]}...")
    data = preprocessor.process_scene(item, save_individual=True)
    if data:
        processed_data.append(data)

# Step 3: Create temporal data cube
if processed_data:
    final_cube = preprocessor.create_time_series_cube(
        processed_data,
        cube_name="central_valley_cube"
    )

    if final_cube:
        print(f"\nüéâ Workflow completed successfully!")
        print(f"   Processed scenes: {len(processed_data)}")
        print(f"   Output directory: {preprocessor.output_dir}")
        print(f"   Data cube shape: {final_cube['red'].shape}")
```

### Create Processing Summary Report

```{python}
# Generate processing summary
output_files = list(preprocessor.output_dir.glob("*.nc"))

print(f"\nüìã Processing Summary Report")
print(f"=" * 50)
print(f"Output Directory: {preprocessor.output_dir}")
print(f"Total Files Created: {len(output_files)}")
print(f"Processing Parameters:")
print(f"  - Target CRS: {preprocessor.target_crs}")
print(f"  - Target Resolution: {preprocessor.target_resolution}m")
print(f"  - Max Cloud Cover: {preprocessor.max_cloud_cover}%")

print(f"\nüìÅ Output Files:")
for file_path in sorted(output_files):
    file_size = file_path.stat().st_size / (1024*1024)  # MB
    print(f"  {file_path.name} ({file_size:.1f} MB)")

# Check if final_cube was created successfully
try:
    if final_cube:
        print(f"\nüìä Final Data Cube Statistics:")
        print(f"  Shape: {final_cube.dims}")
        print(f"  Variables: {list(final_cube.data_vars)}")
        print(f"  Memory usage: ~{final_cube.nbytes / (1024**2):.1f} MB")
except NameError:
    print(f"\nüìä Final Data Cube: Not created (no valid data processed)")

print(f"\nüöÄ Ready for Week 3: Machine Learning on Remote Sensing!")
```

---

## Conclusion

üéâ **Excellent work!** You've built a production-ready preprocessing pipeline for Sentinel-2 imagery.

### What You Accomplished:

1. **Multi-scene Data Discovery**: Searched and organized multiple satellite scenes
2. **Automated Cloud Masking**: Used Scene Classification Layer for quality filtering
3. **Spatial Harmonization**: Reprojected and aligned multiple scenes
4. **Temporal Compositing**: Created cloud-free mosaics using median compositing
5. **Analysis-Ready Data Cubes**: Built time series datasets for analysis
6. **Scalable Workflows**: Implemented batch processing with parallel execution

### Key Takeaways:

- **Scene Classification Layer is powerful** - automates cloud/shadow detection
- **Reprojection is essential** - ensures scenes can be combined seamlessly
- **Temporal compositing reduces clouds** - median filtering creates cleaner datasets
- **Data cubes enable time series analysis** - organize data for trend detection
- **Batch processing scales** - handle large datasets efficiently

### Next Week Preview:

In **Week 3**, we'll use your preprocessed data to **train CNNs on land cover patches**:
- Extract training patches from your data cubes
- Create labeled datasets for supervised learning
- Build and train convolutional neural networks
- Compare different CNN architectures
- Evaluate model performance on real satellite imagery

Your preprocessing pipeline outputs will be the foundation for machine learning workflows!

## Resources

- [Sentinel-2 Scene Classification Layer](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm)
- [Rasterio Reprojection Guide](https://rasterio.readthedocs.io/en/latest/topics/reproject.html)
- [Xarray User Guide for Geosciences](https://docs.xarray.dev/en/stable/user-guide/index.html)
- [Dask for Geospatial Data](https://docs.dask.org/en/latest/array.html)