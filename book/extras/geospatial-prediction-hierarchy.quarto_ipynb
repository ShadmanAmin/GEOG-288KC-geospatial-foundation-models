{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Hierarchy of Geospatial Prediction Tasks\"\n",
        "subtitle: \"From Pixels to Objects: Understanding ML/DL/FM Applications in Remote Sensing\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    code-fold: true\n",
        "    code-tools: true\n",
        "execute:\n",
        "  warning: false\n",
        "  error: false\n",
        "---"
      ],
      "id": "ab2a3551"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| include: false\n",
        "# Generate visualization figures\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Check if figures exist, if not generate them\n",
        "figure_dir = \"images\"\n",
        "figures = [\n",
        "    \"prediction_hierarchy_overview.png\",\n",
        "    \"input_output_relationships.png\", \n",
        "    \"ml_suitability_matrix.png\"\n",
        "]\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(figure_dir, exist_ok=True)\n",
        "\n",
        "# Check if all figures exist\n",
        "all_exist = all(os.path.exists(os.path.join(figure_dir, fig)) for fig in figures)\n",
        "\n",
        "if not all_exist:\n",
        "    # Run the visualization script\n",
        "    try:\n",
        "        exec(open('scripts/visualize_prediction_hierarchy.py').read())\n",
        "    except Exception as e:\n",
        "        print(f\"Note: Could not generate figures automatically. Error: {e}\")\n",
        "        print(\"Please run 'python book/extras/scripts/visualize_prediction_hierarchy.py' manually.\")"
      ],
      "id": "8387fc13",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview\n",
        "\n",
        "In geospatial data science and remote sensing, prediction tasks form a natural hierarchy from pixel-level analysis to complex object understanding. This document explores the relationships between different prediction tasks, their input-output structures, and the suitability of various machine learning approaches.\n",
        "\n",
        "## The Fundamental Dichotomy: Pixel Values vs. Labels\n",
        "\n",
        "At the core of geospatial analysis, we work with two fundamental types of data:\n",
        "\n",
        "![Overview of prediction task hierarchy in geospatial analysis](images/prediction_hierarchy_overview.png)\n",
        "\n",
        "### 1. **Pixel Values** (Continuous Data)\n",
        "- Raw spectral measurements from sensors\n",
        "- Physical quantities (temperature, reflectance, radiance)\n",
        "- Derived indices (NDVI, EVI, moisture indices)\n",
        "- Can be predicted, interpolated, or forecasted\n",
        "\n",
        "### 2. **Labels** (Categorical/Discrete Data)\n",
        "- Human-assigned categories\n",
        "- Land cover classes\n",
        "- Object boundaries and types\n",
        "- Binary masks (water/no water, cloud/clear)\n",
        "\n",
        "## Pixel Value Prediction Tasks\n",
        "\n",
        "When working with continuous pixel values, we encounter two primary prediction paradigms:\n",
        "\n",
        "### Temporal Prediction (Next Value)\n",
        "**Task**: Predict future pixel values based on historical time series\n",
        "**Approach**: Autoregressive models (GPT-like architectures)\n",
        "**Example Applications**:\n",
        "- Vegetation phenology forecasting\n",
        "- Surface temperature prediction\n",
        "- Crop yield estimation\n",
        "\n",
        "```python\n",
        "# Conceptual example\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TemporalPixelPredictor(nn.Module):\n",
        "    \"\"\"GPT-style temporal prediction for pixel time series\"\"\"\n",
        "    def __init__(self, num_bands, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(num_bands, hidden_dim)\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(hidden_dim, nhead=8),\n",
        "            num_layers=6\n",
        "        )\n",
        "        self.predictor = nn.Linear(hidden_dim, num_bands)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch, time, bands)\n",
        "        embedded = self.embedding(x)\n",
        "        # Causal mask for autoregressive prediction\n",
        "        features = self.transformer(embedded)\n",
        "        return self.predictor(features)\n",
        "```\n",
        "\n",
        "### Spatial Prediction (Missing Values)\n",
        "**Task**: Fill in missing pixel values based on spatial context\n",
        "**Approach**: Masked modeling (BERT-like architectures)\n",
        "**Example Applications**:\n",
        "- Cloud gap filling\n",
        "- Sensor failure recovery\n",
        "- Super-resolution\n",
        "- Data fusion across sensors\n",
        "\n",
        "```python\n",
        "class SpatialPixelPredictor(nn.Module):\n",
        "    \"\"\"BERT-style spatial prediction for missing pixels\"\"\"\n",
        "    def __init__(self, num_bands, patch_size=16, hidden_dim=256):\n",
        "        super().__init__()\n",
        "        self.patch_embed = nn.Linear(num_bands * patch_size**2, hidden_dim)\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(hidden_dim, nhead=8),\n",
        "            num_layers=6\n",
        "        )\n",
        "        self.decoder = nn.Linear(hidden_dim, num_bands * patch_size**2)\n",
        "    \n",
        "    def forward(self, x, mask):\n",
        "        # x shape: (batch, height, width, bands)\n",
        "        # mask indicates missing pixels\n",
        "        patches = self.patchify(x)\n",
        "        embedded = self.patch_embed(patches)\n",
        "        # No causal mask - bidirectional attention\n",
        "        features = self.transformer(embedded)\n",
        "        return self.unpatchify(self.decoder(features))\n",
        "```\n",
        "\n",
        "## Label-Based Prediction Tasks\n",
        "\n",
        "Working with labels introduces a hierarchy of complexity from image-level to pixel-level granularity:\n",
        "\n",
        "### 1. Image Classification\n",
        "**Granularity**: Entire image/scene\n",
        "**Input**: Full image (H × W × Bands)\n",
        "**Output**: Single label per image\n",
        "**Example**: \"This Sentinel-2 tile contains urban area\"\n",
        "\n",
        "### 2. Pixel-wise Classification\n",
        "**Granularity**: Individual pixels\n",
        "**Input**: Image patches or full image\n",
        "**Output**: Label map (H × W × Classes)\n",
        "**Example**: Land cover mapping where each pixel gets a class\n",
        "\n",
        "### 3. Object Detection\n",
        "**Granularity**: Bounding boxes\n",
        "**Input**: Full image\n",
        "**Output**: List of [bbox, class, confidence]\n",
        "**Example**: Detecting buildings, vehicles, or agricultural fields\n",
        "\n",
        "### 4. Object Segmentation\n",
        "**Granularity**: Precise object boundaries\n",
        "**Input**: Full image\n",
        "**Output**: Instance masks + classes\n",
        "**Example**: Delineating individual tree crowns or building footprints\n",
        "\n",
        "## Regression for Novel Variable Prediction\n",
        "\n",
        "Beyond classification, regression tasks predict continuous variables that may not be directly observable:\n",
        "\n",
        "### Pixel-wise Regression Applications\n",
        "\n",
        "1. **Biophysical Parameter Estimation**\n",
        "   - Leaf Area Index (LAI)\n",
        "   - Chlorophyll content\n",
        "   - Soil moisture\n",
        "   - Biomass\n",
        "\n",
        "2. **Environmental Variable Prediction**\n",
        "   - Air quality indices\n",
        "   - Surface temperature\n",
        "   - Precipitation estimates\n",
        "   - Carbon flux\n",
        "\n",
        "3. **Socioeconomic Indicators**\n",
        "   - Population density\n",
        "   - Economic activity\n",
        "   - Energy consumption\n",
        "\n",
        "### Input-Output Relationships for Regression\n",
        "\n",
        "![Input-output relationships for different geospatial tasks](images/input_output_relationships.png)\n",
        "\n",
        "```python\n",
        "class GeospatialRegressor(nn.Module):\n",
        "    \"\"\"General framework for pixel-wise regression\"\"\"\n",
        "    def __init__(self, input_bands, output_variables):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_bands, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            # ... more layers\n",
        "        )\n",
        "        self.decoder = nn.Conv2d(128, output_variables, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # x: (batch, bands, height, width)\n",
        "        features = self.encoder(x)\n",
        "        # Output: (batch, variables, height, width)\n",
        "        return self.decoder(features)\n",
        "```\n",
        "\n",
        "## ML/DL/FM Tool Suitability Matrix\n",
        "\n",
        "![ML/DL/FM suitability matrix for geospatial tasks](images/ml_suitability_matrix.png)\n",
        "\n",
        "| Task Type | Traditional ML | Deep Learning | Foundation Models |\n",
        "|-----------|---------------|---------------|-------------------|\n",
        "| **Image Classification** | Random Forest, SVM on hand-crafted features | CNNs (ResNet, EfficientNet) | CLIP, RemoteCLIP |\n",
        "| **Pixel Classification** | Random Forest per pixel | U-Net, DeepLab | Segment Anything + prompting |\n",
        "| **Object Detection** | Limited (HOG+SVM) | YOLO, Faster R-CNN | DINO, OWL-ViT |\n",
        "| **Instance Segmentation** | Very limited | Mask R-CNN | SAM, OneFormer |\n",
        "| **Temporal Prediction** | ARIMA, Random Forest | LSTM, Temporal CNN | TimesFM, Prithvi |\n",
        "| **Spatial Interpolation** | Kriging, IDW | CNN autoencoders | MAE-based models |\n",
        "| **Biophysical Regression** | Random Forest, SVR | CNN, Vision Transformer | Fine-tuned Prithvi, SatMAE |\n",
        "\n",
        "## Choosing the Right Approach\n",
        "\n",
        "### Use Traditional ML When:\n",
        "- Limited training data available\n",
        "- Interpretability is crucial\n",
        "- Computational resources are constrained\n",
        "- Working with tabular features\n",
        "\n",
        "### Use Deep Learning When:\n",
        "- Large labeled datasets available\n",
        "- Complex spatial patterns exist\n",
        "- High accuracy is priority\n",
        "- GPU resources available\n",
        "\n",
        "### Use Foundation Models When:\n",
        "- Limited task-specific labels\n",
        "- Need zero/few-shot capabilities\n",
        "- Working across multiple sensors/resolutions\n",
        "- Require general feature representations\n",
        "\n",
        "## Practical Implementation Considerations\n",
        "\n",
        "### Data Preparation Pipeline\n",
        "\n",
        "```python\n",
        "class GeospatialDataPipeline:\n",
        "    def __init__(self, task_type):\n",
        "        self.task_type = task_type\n",
        "        \n",
        "    def prepare_data(self, imagery, labels=None):\n",
        "        \"\"\"Prepare data based on task requirements\"\"\"\n",
        "        if self.task_type == \"temporal_prediction\":\n",
        "            # Stack time series\n",
        "            return self.create_time_series_sequences(imagery)\n",
        "        \n",
        "        elif self.task_type == \"spatial_interpolation\":\n",
        "            # Create masked inputs\n",
        "            return self.create_masked_inputs(imagery)\n",
        "        \n",
        "        elif self.task_type == \"pixel_classification\":\n",
        "            # Create patch-label pairs\n",
        "            return self.create_training_patches(imagery, labels)\n",
        "        \n",
        "        elif self.task_type == \"object_detection\":\n",
        "            # Format as COCO-style annotations\n",
        "            return self.create_detection_dataset(imagery, labels)\n",
        "```\n",
        "\n",
        "### Multi-Task Learning Opportunities\n",
        "\n",
        "Many geospatial problems benefit from joint learning:\n",
        "\n",
        "1. **Classification + Regression**: Predict land cover type AND vegetation health\n",
        "2. **Detection + Segmentation**: Locate AND delineate objects\n",
        "3. **Temporal + Spatial**: Fill gaps AND forecast future values\n",
        "\n",
        "## Best Practices and Recommendations\n",
        "\n",
        "### 1. Start Simple, Scale Up\n",
        "- Begin with traditional ML baselines\n",
        "- Move to deep learning with sufficient data\n",
        "- Consider foundation models for generalization\n",
        "\n",
        "### 2. Leverage Pretrained Models\n",
        "- Use ImageNet pretrained encoders as starting points\n",
        "- Fine-tune geospatial foundation models (Prithvi, SatMAE)\n",
        "- Apply transfer learning from similar domains\n",
        "\n",
        "### 3. Handle Geospatial Specifics\n",
        "- Account for coordinate systems and projections\n",
        "- Preserve spatial autocorrelation in train/test splits\n",
        "- Consider atmospheric and seasonal effects\n",
        "\n",
        "### 4. Validate Appropriately\n",
        "- Use spatial and temporal holdouts\n",
        "- Employ domain-specific metrics\n",
        "- Validate against ground truth when available\n",
        "\n",
        "## Code Example: Unified Prediction Framework\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict, Optional, Union\n",
        "\n",
        "class UnifiedGeospatialPredictor(nn.Module):\n",
        "    \"\"\"Flexible architecture for various geospatial tasks\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        input_channels: int,\n",
        "        task_config: Dict[str, any]\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.task_type = task_config['type']\n",
        "        self.input_channels = input_channels\n",
        "        \n",
        "        # Shared encoder\n",
        "        self.encoder = self._build_encoder(input_channels)\n",
        "        \n",
        "        # Task-specific heads\n",
        "        if self.task_type == 'classification':\n",
        "            self.head = nn.Conv2d(256, task_config['num_classes'], 1)\n",
        "        elif self.task_type == 'regression':\n",
        "            self.head = nn.Conv2d(256, task_config['num_outputs'], 1)\n",
        "        elif self.task_type == 'detection':\n",
        "            self.head = self._build_detection_head(task_config)\n",
        "        elif self.task_type == 'temporal':\n",
        "            self.head = self._build_temporal_head(task_config)\n",
        "            \n",
        "    def _build_encoder(self, channels):\n",
        "        \"\"\"Build a flexible encoder backbone\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    \n",
        "    def forward(\n",
        "        self, \n",
        "        x: torch.Tensor,\n",
        "        temporal_mask: Optional[torch.Tensor] = None,\n",
        "        spatial_mask: Optional[torch.Tensor] = None\n",
        "    ) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:\n",
        "        \"\"\"Forward pass adapts to task type\"\"\"\n",
        "        features = self.encoder(x)\n",
        "        \n",
        "        if self.task_type in ['classification', 'regression']:\n",
        "            # Pixel-wise predictions\n",
        "            return self.head(features)\n",
        "        \n",
        "        elif self.task_type == 'detection':\n",
        "            # Return dict with boxes, classes, scores\n",
        "            return self.head(features)\n",
        "        \n",
        "        elif self.task_type == 'temporal':\n",
        "            # Handle sequential data\n",
        "            return self.head(features, temporal_mask)\n",
        "```\n",
        "\n",
        "## Summary\n",
        "\n",
        "The hierarchy of geospatial prediction tasks spans from coarse image-level classification to fine-grained pixel-wise regression. Understanding this hierarchy helps in:\n",
        "\n",
        "1. **Choosing appropriate architectures**: Matching model complexity to task requirements\n",
        "2. **Preparing data correctly**: Structuring inputs and outputs for optimal learning\n",
        "3. **Selecting suitable tools**: Leveraging traditional ML, deep learning, or foundation models based on constraints\n",
        "4. **Designing evaluation strategies**: Using task-appropriate metrics and validation schemes\n",
        "\n",
        "As the field evolves, foundation models increasingly bridge these task types, offering unified architectures that can adapt to multiple prediction scenarios with minimal modification.\n",
        "\n",
        "## Further Reading\n",
        "\n",
        "- [Prithvi: NASA-IBM Geospatial Foundation Model](https://github.com/NASA-IMPACT/Prithvi)\n",
        "- [SatMAE: Masked Autoencoders for Satellite Imagery](https://github.com/sustainlab-group/SatMAE)\n",
        "- [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything)\n",
        "- [TimesFM: Time Series Foundation Model](https://github.com/google-research/timesfm)\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. **Task Comparison**: Implement the same vegetation mapping problem as:\n",
        "   - Image classification (healthy/stressed)\n",
        "   - Pixel classification (detailed vegetation types)\n",
        "   - Regression (NDVI prediction)\n",
        "   \n",
        "2. **Multi-Modal Integration**: Combine optical and radar data for:\n",
        "   - Cloud gap filling (spatial interpolation)\n",
        "   - Crop yield prediction (temporal regression)\n",
        "   \n",
        "3. **Foundation Model Adaptation**: Fine-tune Prithvi for:\n",
        "   - Local land cover classification\n",
        "   - Biophysical parameter estimation"
      ],
      "id": "74753c31"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "or_openalex",
      "language": "python",
      "display_name": "Python (or_openalex)",
      "path": "/Users/kellycaylor/Library/Jupyter/kernels/or_openalex"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}