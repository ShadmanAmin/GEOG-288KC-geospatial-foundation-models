---
title: "TorchGeo Datasets & Transforms"
subtitle: "Geospatial datasets and preprocessing"
jupyter: geoai
format: html
---

## Introduction to TorchGeo

TorchGeo is a PyTorch domain library for geospatial data, providing datasets, samplers, transforms, and pre-trained models for satellite imagery and geospatial applications.

```{python}
import torch
import torchgeo
from torchgeo.datasets import RasterDataset, stack_samples
from torchgeo.transforms import AugmentationSequential
import matplotlib.pyplot as plt
import numpy as np

print(f"TorchGeo version: {torchgeo.__version__}")
print(f"PyTorch version: {torch.__version__}")
```

## Core Dataset Classes

### RasterDataset basics
```{python}
from torchgeo.datasets import RasterDataset
from torchgeo.samplers import RandomGeoSampler
import tempfile
import os
from pathlib import Path

# Create a simple custom dataset
class SampleRasterDataset(RasterDataset):
    """Sample raster dataset for demonstration"""
    
    def __init__(self, root='data', transforms=None):
        super().__init__(root, transforms=transforms)
        self.root = Path(root)
        
    def __getitem__(self, query):
        # This would normally load real raster data
        # For demo, create synthetic data
        sample = {
            'image': torch.rand(3, 256, 256),  # RGB image
            'bbox': query,
            'crs': 'EPSG:4326'
        }
        
        if self.transforms:
            sample = self.transforms(sample)
            
        return sample

# Initialize dataset
dataset = SampleRasterDataset()
print(f"Dataset created: {type(dataset).__name__}")
```

### VisionDataset examples
```{python}
from torchgeo.datasets import RESISC45, EuroSAT

# Note: These require downloaded data files
# For demonstration, we show the usage patterns

# RESISC45 - Remote sensing image scene classification
# resisc45 = RESISC45(root='data/resisc45', download=True)
# print(f"RESISC45 classes: {len(resisc45.classes)}")

# EuroSAT - Sentinel-2 image classification  
# eurosat = EuroSAT(root='data/eurosat', download=True)
# print(f"EuroSAT classes: {len(eurosat.classes)}")

print("Vision dataset classes ready for use with downloaded data")
```

## Geospatial Sampling

### RandomGeoSampler
```{python}
from torchgeo.samplers import RandomGeoSampler, GridGeoSampler
from torchgeo.datasets import BoundingBox

# Define a region of interest
roi = BoundingBox(
    minx=-10.0, maxx=10.0,
    miny=-10.0, maxy=10.0,
    mint=0, maxt=100
)

# Random sampling
random_sampler = RandomGeoSampler(
    dataset=dataset,
    size=256,  # Patch size in pixels
    length=100,  # Number of samples per epoch
    roi=roi
)

print(f"Random sampler length: {len(random_sampler)}")
print(f"Sample query: {next(iter(random_sampler))}")
```

### GridGeoSampler
```{python}
# Grid-based systematic sampling
grid_sampler = GridGeoSampler(
    dataset=dataset,
    size=256,
    stride=128,  # Overlap between patches
    roi=roi
)

print(f"Grid sampler length: {len(grid_sampler)}")
print("Grid sampler provides systematic coverage")
```

## Data Transforms

### Basic transforms
```{python}
import torchvision.transforms as T
from torchgeo.transforms import AugmentationSequential

# Standard computer vision transforms
basic_transforms = T.Compose([
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# TorchGeo augmentation sequence (preserves geospatial properties)
geo_transforms = AugmentationSequential(
    T.RandomHorizontalFlip(p=0.5),
    T.RandomVerticalFlip(p=0.5),
    T.RandomRotation(degrees=90),
    data_keys=['image']
)

print("Transform sequences created")
```

### Geospatial-aware transforms
```{python}
# Create sample data to demonstrate transforms
sample_data = {
    'image': torch.rand(3, 256, 256),
    'mask': torch.randint(0, 5, (256, 256)),
    'bbox': BoundingBox(-1, 1, -1, 1, 0, 1)
}

# Apply transforms
transformed = geo_transforms(sample_data)

print(f"Original image shape: {sample_data['image'].shape}")
print(f"Transformed image shape: {transformed['image'].shape}")
print(f"Mask preserved: {transformed['mask'].shape}")
```

## Working with Real Satellite Data

### Landsat dataset example
```{python}
from torchgeo.datasets import Landsat8

# Note: Requires actual Landsat data
# landsat = Landsat8(root='data/landsat8')

# Define query for specific area and time
query = BoundingBox(
    minx=-100.0, maxx=-99.0,  # Longitude
    miny=40.0, maxy=41.0,     # Latitude  
    mint=637110000,           # Time (Unix timestamp)
    maxt=637196400
)

# Sample usage pattern:
# sample = landsat[query]
# print(f"Landsat sample keys: {sample.keys()}")

print("Landsat dataset pattern demonstrated")
```

### Sentinel-2 dataset example  
```{python}
from torchgeo.datasets import Sentinel2

# Sentinel-2 usage pattern
# sentinel = Sentinel2(root='data/sentinel2')
# s2_sample = sentinel[query]

print("Sentinel-2 dataset pattern demonstrated")
```

## Multi-modal Data Fusion

### Combining datasets
```{python}
from torchgeo.datasets import IntersectionDataset, UnionDataset

# Example of combining multiple data sources
class DEMDataset(RasterDataset):
    """Digital Elevation Model dataset"""
    def __getitem__(self, query):
        return {
            'elevation': torch.rand(1, 256, 256),
            'bbox': query
        }

class LandcoverDataset(RasterDataset):
    """Land cover classification dataset"""  
    def __getitem__(self, query):
        return {
            'landcover': torch.randint(0, 10, (256, 256)),
            'bbox': query
        }

# Create datasets
optical_ds = SampleRasterDataset()
dem_ds = DEMDataset() 
landcover_ds = LandcoverDataset()

# Combine using intersection (data must exist in all datasets)
fused_ds = IntersectionDataset(optical_ds, dem_ds, landcover_ds)

print(f"Fused dataset created with {len(fused_ds.datasets)} components")
```

### Stack samples utility
```{python}
# Create multiple samples to stack
samples = []
for i in range(4):
    sample = {
        'image': torch.rand(3, 64, 64),
        'mask': torch.randint(0, 2, (64, 64)),
        'elevation': torch.rand(1, 64, 64)
    }
    samples.append(sample)

# Stack into batch
batch = stack_samples(samples)

print(f"Batch image shape: {batch['image'].shape}")
print(f"Batch mask shape: {batch['mask'].shape}")
print(f"Batch elevation shape: {batch['elevation'].shape}")
```

## DataModule for Training

### Lightning DataModule
```{python}
import pytorch_lightning as pl
from torch.utils.data import DataLoader

class GeospatialDataModule(pl.LightningDataModule):
    """Data module for geospatial training"""
    
    def __init__(self, dataset, batch_size=32, num_workers=4):
        super().__init__()
        self.dataset = dataset
        self.batch_size = batch_size
        self.num_workers = num_workers
        
    def setup(self, stage=None):
        # Split dataset
        total_size = 1000  # Example size
        train_size = int(0.8 * total_size)
        val_size = total_size - train_size
        
        # Create samplers for different splits
        self.train_sampler = RandomGeoSampler(
            self.dataset, size=256, length=train_size
        )
        self.val_sampler = RandomGeoSampler(
            self.dataset, size=256, length=val_size
        )
    
    def train_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.train_sampler,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            collate_fn=stack_samples
        )
    
    def val_dataloader(self):
        return DataLoader(
            self.dataset,
            sampler=self.val_sampler,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            collate_fn=stack_samples
        )

# Initialize data module
datamodule = GeospatialDataModule(dataset, batch_size=8)
datamodule.setup()

print("Geospatial data module ready for training")
```

## Pre-trained Models

### Using TorchGeo models
```{python}
from torchgeo.models import ResNet18_Weights
import torchvision.models as models

# Load pre-trained weights for satellite imagery
# weights = ResNet18_Weights.SENTINEL2_ALL_MOCO
# model = models.resnet18(weights=weights)

# For demonstration without actual weights:
model = models.resnet18(pretrained=False)
model.conv1 = torch.nn.Conv2d(
    in_channels=12,  # Sentinel-2 has 12 bands
    out_channels=64,
    kernel_size=7,
    stride=2,
    padding=3,
    bias=False
)

print(f"Model adapted for {model.conv1.in_channels} input channels")
```

### Fine-tuning for classification
```{python}
import torch.nn as nn

class GeospatialClassifier(nn.Module):
    """Classifier for geospatial data"""
    
    def __init__(self, backbone, num_classes=10):
        super().__init__()
        self.backbone = backbone
        
        # Replace classifier head
        if hasattr(backbone, 'fc'):
            in_features = backbone.fc.in_features
            backbone.fc = nn.Linear(in_features, num_classes)
        
    def forward(self, x):
        return self.backbone(x)

# Create classifier
classifier = GeospatialClassifier(model, num_classes=10)
print(f"Classifier created for {classifier.backbone.fc.out_features} classes")
```

## Visualization and Inspection

### Plotting samples
```{python}
def plot_sample(sample, figsize=(12, 4)):
    """Plot a geospatial sample"""
    fig, axes = plt.subplots(1, 3, figsize=figsize)
    
    # RGB image (first 3 channels)
    if 'image' in sample:
        image = sample['image']
        if image.shape[0] >= 3:
            rgb = image[:3].permute(1, 2, 0)
            # Normalize for display
            rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min())
            axes[0].imshow(rgb)
            axes[0].set_title('RGB Composite')
            axes[0].axis('off')
    
    # Mask/labels
    if 'mask' in sample:
        mask = sample['mask']
        axes[1].imshow(mask, cmap='tab10')
        axes[1].set_title('Mask/Labels')
        axes[1].axis('off')
    
    # Additional data (e.g., elevation)
    if 'elevation' in sample:
        elev = sample['elevation'].squeeze()
        im = axes[2].imshow(elev, cmap='terrain')
        axes[2].set_title('Elevation')
        axes[2].axis('off')
        plt.colorbar(im, ax=axes[2], shrink=0.8)
    
    plt.tight_layout()
    plt.show()

# Create and plot a sample
demo_sample = {
    'image': torch.rand(3, 128, 128),
    'mask': torch.randint(0, 5, (128, 128)),
    'elevation': torch.rand(1, 128, 128) * 1000
}

plot_sample(demo_sample)
```

### Dataset statistics
```{python}
def compute_dataset_stats(dataloader, num_samples=100):
    """Compute dataset statistics for normalization"""
    
    pixel_sum = torch.zeros(3)
    pixel_squared_sum = torch.zeros(3)
    num_pixels = 0
    
    for i, batch in enumerate(dataloader):
        if i >= num_samples:
            break
            
        images = batch['image']
        batch_size, channels, height, width = images.shape
        num_pixels += batch_size * height * width
        
        pixel_sum += images.sum(dim=[0, 2, 3])
        pixel_squared_sum += (images ** 2).sum(dim=[0, 2, 3])
    
    mean = pixel_sum / num_pixels
    var = (pixel_squared_sum / num_pixels) - (mean ** 2)
    std = torch.sqrt(var)
    
    return mean, std

# Example usage (would require actual dataloader)
# mean, std = compute_dataset_stats(train_loader)
# print(f"Dataset mean: {mean}")
# print(f"Dataset std: {std}")

print("Dataset statistics computation function ready")
```

## Advanced Features

### Custom indices and bands
```{python}
class SpectralIndices:
    """Common spectral indices for satellite imagery"""
    
    @staticmethod
    def ndvi(red, nir):
        """Normalized Difference Vegetation Index"""
        return (nir - red) / (nir + red + 1e-8)
    
    @staticmethod
    def ndwi(green, nir):
        """Normalized Difference Water Index"""
        return (green - nir) / (green + nir + 1e-8)
    
    @staticmethod
    def evi(blue, red, nir, g=2.5, c1=6.0, c2=7.5, l=1.0):
        """Enhanced Vegetation Index"""
        return g * (nir - red) / (nir + c1 * red - c2 * blue + l)

# Example with Sentinel-2 bands (simulated)
s2_image = torch.rand(12, 256, 256)  # 12 Sentinel-2 bands

# Extract specific bands (0-indexed)
blue = s2_image[1]    # B2
green = s2_image[2]   # B3  
red = s2_image[3]     # B4
nir = s2_image[7]     # B8

# Calculate indices
ndvi = SpectralIndices.ndvi(red, nir)
ndwi = SpectralIndices.ndwi(green, nir)
evi = SpectralIndices.evi(blue, red, nir)

print(f"NDVI shape: {ndvi.shape}, range: [{ndvi.min():.3f}, {ndvi.max():.3f}]")
print(f"NDWI shape: {ndwi.shape}, range: [{ndwi.min():.3f}, {ndwi.max():.3f}]")
```

### Temporal data handling
```{python}
class TemporalDataset(RasterDataset):
    """Dataset for temporal satellite imagery"""
    
    def __init__(self, root, time_steps=5):
        super().__init__(root)
        self.time_steps = time_steps
    
    def __getitem__(self, query):
        # Simulate temporal data
        temporal_images = []
        
        for t in range(self.time_steps):
            # Each time step has slightly different data
            image = torch.rand(3, 256, 256) + t * 0.1
            temporal_images.append(image)
        
        return {
            'image': torch.stack(temporal_images, dim=0),  # [T, C, H, W]
            'bbox': query,
            'timestamps': torch.arange(self.time_steps)
        }

# Create temporal dataset
temporal_ds = TemporalDataset('data', time_steps=5)
print("Temporal dataset created for time series analysis")
```

## Performance Optimization

### Caching and preprocessing
```{python}
class CachedDataset(RasterDataset):
    """Dataset with caching for repeated access"""
    
    def __init__(self, root, cache_size=1000):
        super().__init__(root)
        self.cache = {}
        self.cache_size = cache_size
    
    def __getitem__(self, query):
        query_key = str(query)
        
        if query_key in self.cache:
            return self.cache[query_key]
        
        # Generate/load data
        sample = {
            'image': torch.rand(3, 256, 256),
            'bbox': query
        }
        
        # Cache if space available
        if len(self.cache) < self.cache_size:
            self.cache[query_key] = sample
        
        return sample

print("Cached dataset implementation ready")
```

### Memory-efficient loading
```{python}
def create_efficient_dataloader(dataset, batch_size=32, num_workers=4):
    """Create memory-efficient dataloader"""
    
    sampler = RandomGeoSampler(dataset, size=256, length=1000)
    
    return DataLoader(
        dataset,
        sampler=sampler,
        batch_size=batch_size,
        num_workers=num_workers,
        collate_fn=stack_samples,
        pin_memory=True,  # Faster GPU transfer
        persistent_workers=True,  # Keep workers alive
        prefetch_factor=2  # Prefetch batches
    )

print("Efficient dataloader configuration ready")
```

## Summary

Key TorchGeo concepts:
- **RasterDataset**: Base class for raster data
- **VisionDataset**: Classification datasets (RESISC45, EuroSAT)
- **GeoSampler**: Spatial sampling strategies
- **Transforms**: Geospatial-aware data augmentation
- **DataModule**: PyTorch Lightning integration
- **Multi-modal**: Combining different data sources
- **Pre-trained models**: Domain-specific model weights
- **Spectral indices**: Vegetation, water, soil indices
