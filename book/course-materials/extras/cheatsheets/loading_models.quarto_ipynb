{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Loading Pre-trained Models\"\n",
        "subtitle: \"Working with HuggingFace model hub\"\n",
        "jupyter: geoai\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Loading Pre-trained Models\n",
        "\n",
        "This cheatsheet shows how to load and work with pre-trained models for geospatial AI, using real examples with small sample data.\n",
        "\n",
        "## Setup and Imports\n"
      ],
      "id": "28704484"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"TIMM available: âœ“\")\n",
        "\n",
        "# Set random seeds for reproducible results\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "id": "374bad5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TIMM (Torch Image Models) - Quick and Reliable\n",
        "\n",
        "TIMM is the most reliable way to load pre-trained vision models. Let's start with a small ResNet model.\n"
      ],
      "id": "dc93dd3b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load a lightweight ResNet model\n",
        "model = timm.create_model('resnet18', pretrained=True, num_classes=10)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model: {model.__class__.__name__}\")\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# Check input requirements\n",
        "data_config = timm.data.resolve_model_data_config(model)\n",
        "print(f\"Expected input size: {data_config['input_size']}\")\n",
        "print(f\"Mean: {data_config['mean']}\")\n",
        "print(f\"Std: {data_config['std']}\")"
      ],
      "id": "6449b996",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adapting RGB Models for Satellite Data\n",
        "\n",
        "Most models expect 3-channel RGB, but satellite data has more bands. Here's how to adapt:\n"
      ],
      "id": "ac4b8588"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def adapt_first_layer_for_multispectral(model, num_bands=6):\n",
        "    \"\"\"Adapt the first convolutional layer for multi-band input\"\"\"\n",
        "    \n",
        "    # Find the first conv layer\n",
        "    first_conv = None\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            first_conv = module\n",
        "            first_conv_name = name\n",
        "            break\n",
        "    \n",
        "    if first_conv is None:\n",
        "        return model\n",
        "    \n",
        "    # Get original weights\n",
        "    old_weight = first_conv.weight.data  # [out_channels, in_channels, H, W]\n",
        "    \n",
        "    # Create new layer with more input channels\n",
        "    new_conv = nn.Conv2d(\n",
        "        num_bands, \n",
        "        first_conv.out_channels,\n",
        "        first_conv.kernel_size,\n",
        "        first_conv.stride,\n",
        "        first_conv.padding,\n",
        "        bias=first_conv.bias is not None\n",
        "    )\n",
        "    \n",
        "    # Initialize new weights by repeating/averaging RGB channels\n",
        "    with torch.no_grad():\n",
        "        if num_bands >= 3:\n",
        "            # Copy RGB weights\n",
        "            new_conv.weight[:, :3] = old_weight\n",
        "            # Initialize extra bands as average of RGB\n",
        "            for i in range(3, num_bands):\n",
        "                new_conv.weight[:, i:i+1] = old_weight.mean(dim=1, keepdim=True)\n",
        "        else:\n",
        "            # Use first num_bands from original\n",
        "            new_conv.weight = old_weight[:, :num_bands]\n",
        "        \n",
        "        # Copy bias\n",
        "        if first_conv.bias is not None:\n",
        "            new_conv.bias.data = first_conv.bias.data\n",
        "    \n",
        "    # Replace the layer\n",
        "    setattr(model, first_conv_name.split('.')[-1], new_conv)\n",
        "    \n",
        "    print(f\"Adapted {first_conv_name}: {old_weight.shape[1]} -> {num_bands} input channels\")\n",
        "    return model\n",
        "\n",
        "# Create a 6-band version of ResNet\n",
        "model_6band = timm.create_model('resnet18', pretrained=True, num_classes=10)\n",
        "model_6band = adapt_first_layer_for_multispectral(model_6band, num_bands=6)\n",
        "model_6band.eval()\n",
        "\n",
        "print(f\"Original input channels: 3\")\n",
        "print(f\"Adapted input channels: 6\")"
      ],
      "id": "681367fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Inference Example\n"
      ],
      "id": "41dc2c40"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create sample satellite-like data (6 bands, 224x224)\n",
        "sample_data = torch.randn(1, 6, 224, 224)\n",
        "print(f\"Sample data shape: {sample_data.shape}\")\n",
        "\n",
        "# Test the adapted model\n",
        "with torch.no_grad():\n",
        "    output = model_6band(sample_data)\n",
        "    predictions = torch.softmax(output, dim=1)\n",
        "\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Top 3 predictions: {predictions[0].topk(3)[0].numpy()}\")"
      ],
      "id": "7846f037",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Preprocessing Pipeline\n"
      ],
      "id": "4937df23"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SatellitePreprocessor:\n",
        "    \"\"\"Simple preprocessing for satellite imagery\"\"\"\n",
        "    \n",
        "    def __init__(self, input_size=224, num_bands=6):\n",
        "        self.input_size = input_size\n",
        "        self.num_bands = num_bands\n",
        "        \n",
        "        # Typical normalization for satellite data\n",
        "        self.mean = [0.485, 0.456, 0.406, 0.5, 0.3, 0.2][:num_bands]\n",
        "        self.std = [0.229, 0.224, 0.225, 0.2, 0.15, 0.12][:num_bands]\n",
        "    \n",
        "    def __call__(self, image_tensor):\n",
        "        \"\"\"Normalize image tensor\"\"\"\n",
        "        # Ensure correct shape [C, H, W] or [B, C, H, W]\n",
        "        if image_tensor.dim() == 3:\n",
        "            image_tensor = image_tensor.unsqueeze(0)\n",
        "        \n",
        "        # Resize if needed\n",
        "        if image_tensor.shape[-1] != self.input_size:\n",
        "            image_tensor = nn.functional.interpolate(\n",
        "                image_tensor, size=(self.input_size, self.input_size), \n",
        "                mode='bilinear', align_corners=False\n",
        "            )\n",
        "        \n",
        "        # Normalize\n",
        "        mean = torch.tensor(self.mean).view(1, -1, 1, 1)\n",
        "        std = torch.tensor(self.std).view(1, -1, 1, 1)\n",
        "        \n",
        "        normalized = (image_tensor - mean) / std\n",
        "        return normalized\n",
        "\n",
        "# Test preprocessing\n",
        "preprocessor = SatellitePreprocessor(input_size=224, num_bands=6)\n",
        "raw_data = torch.rand(6, 256, 256)  # Raw satellite patch\n",
        "\n",
        "preprocessed = preprocessor(raw_data)\n",
        "print(f\"Raw data: {raw_data.shape} -> Preprocessed: {preprocessed.shape}\")\n",
        "print(f\"Raw range: [{raw_data.min():.3f}, {raw_data.max():.3f}]\")\n",
        "print(f\"Preprocessed range: [{preprocessed.min():.3f}, {preprocessed.max():.3f}]\")"
      ],
      "id": "f01d3fd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Extraction\n"
      ],
      "id": "b7a45cc2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_features(model, data, layer_name='avgpool'):\n",
        "    \"\"\"Extract features from a specific layer\"\"\"\n",
        "    \n",
        "    features = {}\n",
        "    \n",
        "    def hook(name):\n",
        "        def fn(module, input, output):\n",
        "            features[name] = output.detach()\n",
        "        return fn\n",
        "    \n",
        "    # Register hook\n",
        "    for name, module in model.named_modules():\n",
        "        if layer_name in name:\n",
        "            handle = module.register_forward_hook(hook(name))\n",
        "            break\n",
        "    \n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        _ = model(data)\n",
        "    \n",
        "    # Clean up\n",
        "    handle.remove()\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Extract features from our sample\n",
        "features = extract_features(model_6band, sample_data, 'avgpool')\n",
        "feature_name = list(features.keys())[0]\n",
        "feature_tensor = features[feature_name]\n",
        "\n",
        "print(f\"Feature layer: {feature_name}\")\n",
        "print(f\"Feature shape: {feature_tensor.shape}\")\n",
        "print(f\"Feature stats: mean={feature_tensor.mean():.3f}, std={feature_tensor.std():.3f}\")"
      ],
      "id": "a250809c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Band Selection Utilities\n"
      ],
      "id": "424d7d03"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class BandSelector:\n",
        "    \"\"\"Select specific bands for different visualizations\"\"\"\n",
        "    \n",
        "    # Common band combinations for Landsat-8\n",
        "    COMBINATIONS = {\n",
        "        'rgb': [3, 2, 1],        # True color (Red, Green, Blue)\n",
        "        'false_color': [4, 3, 2], # False color (NIR, Red, Green)\n",
        "        'swir': [6, 5, 4],       # SWIR composite\n",
        "        'agriculture': [5, 4, 3]  # Agriculture (SWIR1, NIR, Red)\n",
        "    }\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def select_bands(self, image, combination='rgb'):\n",
        "        \"\"\"Select 3 bands for visualization\"\"\"\n",
        "        if combination not in self.COMBINATIONS:\n",
        "            print(f\"Unknown combination. Available: {list(self.COMBINATIONS.keys())}\")\n",
        "            return image[:3]  # Return first 3 bands\n",
        "        \n",
        "        indices = [i-1 for i in self.COMBINATIONS[combination]]  # Convert to 0-indexed\n",
        "        \n",
        "        if image.dim() == 3:  # [C, H, W]\n",
        "            return image[indices]\n",
        "        elif image.dim() == 4:  # [B, C, H, W]\n",
        "            return image[:, indices]\n",
        "    \n",
        "    def visualize_bands(self, image, combination='rgb'):\n",
        "        \"\"\"Create a simple visualization\"\"\"\n",
        "        selected = self.select_bands(image, combination)\n",
        "        \n",
        "        if selected.dim() == 4:\n",
        "            selected = selected[0]  # Take first batch item\n",
        "        \n",
        "        # Convert to numpy and normalize for display\n",
        "        vis_data = selected.permute(1, 2, 0).numpy()\n",
        "        vis_data = (vis_data - vis_data.min()) / (vis_data.max() - vis_data.min())\n",
        "        \n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(vis_data)\n",
        "        plt.title(f'{combination.upper()} Visualization')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Test band selection\n",
        "selector = BandSelector()\n",
        "sample_6band = torch.rand(6, 128, 128)\n",
        "\n",
        "rgb_bands = selector.select_bands(sample_6band, 'rgb')\n",
        "print(f\"Original: {sample_6band.shape} -> RGB: {rgb_bands.shape}\")\n",
        "\n",
        "# Show available combinations\n",
        "print(f\"Available band combinations: {list(selector.COMBINATIONS.keys())}\")"
      ],
      "id": "37b637fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Inference Wrapper\n"
      ],
      "id": "8bc3205b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SimpleInference:\n",
        "    \"\"\"Simple inference wrapper for geospatial models\"\"\"\n",
        "    \n",
        "    def __init__(self, model, preprocessor=None):\n",
        "        self.model = model\n",
        "        self.preprocessor = preprocessor\n",
        "        self.model.eval()\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def predict(self, image_tensor, return_features=False):\n",
        "        \"\"\"Run prediction on image tensor\"\"\"\n",
        "        \n",
        "        # Preprocess if needed\n",
        "        if self.preprocessor:\n",
        "            image_tensor = self.preprocessor(image_tensor)\n",
        "        \n",
        "        # Ensure batch dimension\n",
        "        if image_tensor.dim() == 3:\n",
        "            image_tensor = image_tensor.unsqueeze(0)\n",
        "        \n",
        "        # Forward pass\n",
        "        output = self.model(image_tensor)\n",
        "        \n",
        "        if return_features:\n",
        "            # Extract features from avgpool layer\n",
        "            features = extract_features(self.model, image_tensor, 'avgpool')\n",
        "            return output, features\n",
        "        \n",
        "        return output\n",
        "    \n",
        "    def predict_proba(self, image_tensor):\n",
        "        \"\"\"Get class probabilities\"\"\"\n",
        "        logits = self.predict(image_tensor)\n",
        "        return torch.softmax(logits, dim=1)\n",
        "\n",
        "# Create inference wrapper\n",
        "inference = SimpleInference(model_6band, preprocessor)\n",
        "\n",
        "# Test inference\n",
        "test_image = torch.rand(6, 200, 200)\n",
        "probabilities = inference.predict_proba(test_image)\n",
        "\n",
        "print(f\"Input: {test_image.shape}\")\n",
        "print(f\"Predictions shape: {probabilities.shape}\")\n",
        "print(f\"Top 3 classes: {probabilities[0].topk(3)[1].tolist()}\")\n",
        "print(f\"Top 3 probabilities: {probabilities[0].topk(3)[0].tolist()}\")"
      ],
      "id": "75ceccbd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "- **TIMM models** are reliable and easy to load\n",
        "- **Adapt the first layer** for multi-spectral satellite data\n",
        "- **Use proper preprocessing** with band-specific normalization\n",
        "- **Extract features** using forward hooks for analysis\n",
        "- **Band selection** enables different visualization modes\n",
        "- **Inference wrappers** simplify model deployment\n",
        "\n",
        "These patterns work with any vision model and can be extended for more complex geospatial applications."
      ],
      "id": "bd853e56"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "geoai",
      "language": "python",
      "display_name": "GeoAI",
      "path": "/Users/kellycaylor/Library/Jupyter/kernels/geoai"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}