[
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Building Geospatial Foundation Models",
    "section": "Course Description",
    "text": "Course Description\nThis project-driven seminar teaches students to build geospatial foundation models (GFMs) from scratch. Students implement every layer of the pipeline—from data pipelines and tokenization through attention mechanisms, full architectures, pretraining, evaluation, and deployment—culminating in a working end-to-end GFM tailored to a chosen geospatial application.\nBy the end of the course, students will be able to:\n\nDesign and implement geospatial data pipelines for multi-spectral, spatial, and temporal data\nBuild attention mechanisms and assemble transformer-based architectures for geospatial inputs\nPretrain using masked autoencoding and evaluate learned representations\nFine-tune models for specific Earth observation tasks\nDeploy models via APIs and interactive interfaces with honest performance analysis"
  },
  {
    "objectID": "index.html#getting-started-with-the-ucsb-ai-sandbox",
    "href": "index.html#getting-started-with-the-ucsb-ai-sandbox",
    "title": "Building Geospatial Foundation Models",
    "section": "Getting Started with the UCSB AI Sandbox",
    "text": "Getting Started with the UCSB AI Sandbox\nHere are detailed instructions for setting up your environment on the UCSB AI Sandbox, including foundation model installation and GPU optimization."
  },
  {
    "objectID": "index.html#course-structure-3-stages-10-weeks",
    "href": "index.html#course-structure-3-stages-10-weeks",
    "title": "Building Geospatial Foundation Models",
    "section": "Course Structure: 3 Stages, 10 Weeks",
    "text": "Course Structure: 3 Stages, 10 Weeks\n\n\n\n\n\nflowchart TD\n    subgraph Stage1 [\"🏗️ Stage 1: Build GFM Architecture\"]\n        direction LR\n        W1[\"📊&lt;br/&gt;Week 1&lt;br/&gt;Data Foundations&lt;br/&gt;Pipelines & Tokenization\"] --&gt; W2[\"🧠&lt;br/&gt;Week 2&lt;br/&gt;Attention Mechanisms&lt;br/&gt;Spatial-Temporal Focus\"]\n        W2 --&gt; W3[\"🏛️&lt;br/&gt;Week 3&lt;br/&gt;Complete Architecture&lt;br/&gt;Vision Transformer\"]\n    end\n    \n    subgraph Stage2 [\"🚀 Stage 2: Train Foundation Model\"]\n        direction LR\n        W4[\"🎭&lt;br/&gt;Week 4&lt;br/&gt;Pretraining&lt;br/&gt;Masked Autoencoder\"] --&gt; W5[\"⚡&lt;br/&gt;Week 5&lt;br/&gt;Training Optimization&lt;br/&gt;Stability & Efficiency\"]\n        W5 --&gt; W6[\"📈&lt;br/&gt;Week 6&lt;br/&gt;Evaluation & Analysis&lt;br/&gt;Embeddings & Probing\"]\n        W6 --&gt; W7[\"🔗&lt;br/&gt;Week 7&lt;br/&gt;Model Integration&lt;br/&gt;Prithvi, SatMAE\"]\n    end\n    \n    subgraph Stage3 [\"🎯 Stage 3: Apply & Deploy\"]\n        direction LR\n        W8[\"🎯&lt;br/&gt;Week 8&lt;br/&gt;Fine-tuning&lt;br/&gt;Task-Specific Training\"] --&gt; W9[\"🚀&lt;br/&gt;Week 9&lt;br/&gt;Deployment&lt;br/&gt;APIs & Interfaces\"]\n        W9 --&gt; W10[\"🎤&lt;br/&gt;Week 10&lt;br/&gt;Presentations&lt;br/&gt;Project Synthesis\"]\n    end\n    \n    Stage1 --&gt; Stage2\n    Stage2 --&gt; Stage3\n    \n    style Stage1 fill:#e3f2fd\n    style Stage2 fill:#fff3e0  \n    style Stage3 fill:#e8f5e8\n    style W1 fill:#bbdefb\n    style W4 fill:#ffe0b2\n    style W8 fill:#c8e6c8\n\n\n\n\n\n\n\n🏗️ Stage 1: Build GFM Architecture (Weeks 1-3)\n\nWeek 1: Geospatial Data Foundations (data pipelines, tokenization, loaders)\nWeek 2: Spatial-Temporal Attention Mechanisms (from-scratch implementation)\nWeek 3: Complete GFM Architecture (Vision Transformer for geospatial)\n\n\n\n🚀 Stage 2: Train a Foundation Model (Weeks 4-7)\n\nWeek 4: Pretraining Implementation (masked autoencoder)\nWeek 5: Training Loop Optimization (stability, efficiency, mixed precision)\nWeek 6: Model Evaluation & Analysis (embeddings, probing, reconstructions)\nWeek 7: Integration with Existing Models (Prithvi, SatMAE)\n\n\n\n🎯 Stage 3: Apply & Deploy (Weeks 8-10)\n\nWeek 8: Task-Specific Fine-tuning (efficient strategies, few-shot)\nWeek 9: Model Implementation & Deployment (APIs, UI, benchmarking)\nWeek 10: Project Presentations & Synthesis\n\nQuick links:\n\nWeekly materials: see navbar → 🗓️ weekly materials\nInteractive sessions: see navbar → 💻 interactive sessions"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Building Geospatial Foundation Models",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\n\n\nInstructor\n\n\n\n\n\n\n\nKelly Caylor\nEmail: caylor@ucsb.edu\nLearn more: Bren profile\n\n\n\n\nTA\n\n\n\n\n\n\n\nAnna Boser\nEmail: anaboser@ucsb.edu\nLearn more: Bren profile"
  },
  {
    "objectID": "cheatsheets.html",
    "href": "cheatsheets.html",
    "title": "Cheatsheets",
    "section": "",
    "text": "Working with Rasterio\nEarth Engine Basics\nXarray for Multi-dimensional Data"
  },
  {
    "objectID": "cheatsheets.html#geospatial-data-fundamentals",
    "href": "cheatsheets.html#geospatial-data-fundamentals",
    "title": "Cheatsheets",
    "section": "",
    "text": "Working with Rasterio\nEarth Engine Basics\nXarray for Multi-dimensional Data"
  },
  {
    "objectID": "cheatsheets.html#pytorch-for-geospatial-ai",
    "href": "cheatsheets.html#pytorch-for-geospatial-ai",
    "title": "Cheatsheets",
    "section": "🔥 PyTorch for Geospatial AI",
    "text": "🔥 PyTorch for Geospatial AI\n\nPyTorch Tensors & GPU Operations\nTorchGeo Datasets & Transforms\nData Loading for Satellite Imagery"
  },
  {
    "objectID": "cheatsheets.html#foundation-models-huggingface",
    "href": "cheatsheets.html#foundation-models-huggingface",
    "title": "Cheatsheets",
    "section": "🤗 Foundation Models & HuggingFace",
    "text": "🤗 Foundation Models & HuggingFace\n\nLoading Pre-trained Models\nModel Inference & Feature Extraction\nFine-tuning Strategies"
  },
  {
    "objectID": "cheatsheets.html#visualization-analysis",
    "href": "cheatsheets.html#visualization-analysis",
    "title": "Cheatsheets",
    "section": "📊 Visualization & Analysis",
    "text": "📊 Visualization & Analysis\n\nPlotting Satellite Imagery\nInteractive Maps with Folium\nGeospatial Plotting with Matplotlib"
  },
  {
    "objectID": "course-materials/week8.html",
    "href": "course-materials/week8.html",
    "title": "Real-World Application",
    "section": "",
    "text": "This week adapts foundation models for specific tasks using efficient fine-tuning strategies.\n\n\n\nAdapt foundation models for specific tasks\nImplement efficient fine-tuning strategies\nHandle limited labeled data\nEvaluate task performance\n\n\n\n\n\nFull Fine-tuning vs. Parameter-efficient: LoRA and adapter strategies\nFew-shot Learning: Working with limited labeled data\nTask-specific Data: Preparation and augmentation strategies\nMulti-task Learning: Joint training for multiple objectives\nFine-tuning Evaluation: Task-specific performance metrics\n\n\n\n\n\nImplement LoRA and adapter-based fine-tuning\nPrepare task-specific datasets\nCompare full vs. parameter-efficient fine-tuning\nEvaluate few-shot learning capabilities\nOptimize for limited data scenarios\n\n\n\n\nSession 8: Task-Specific Fine-tuning - Efficient fine-tuning strategies and performance optimization\n\n\n\n\nOptimization and feature development work\nSystem testing and validation across scenarios\nDocumentation and user guide creation\nFinal debugging and system refinement\n\n\n\n\nFine-tuned model for chosen application with performance analysis and comparison\n\n\n\n\nComputational Efficiency: Algorithm optimization, parallel processing, memory management\nSystem Architecture: Modular design, component interaction, API development\nUser Experience: Interface improvements, workflow automation, result visualization\nDeployment Readiness: Configuration management, environment portability, monitoring\n\n\n\n\n\nDistributed computing and cloud deployment patterns\nModel serving and API development best practices\nAdvanced visualization and interactive dashboard creation\nSystem monitoring, logging, and error tracking implementation\n\n\n\n\n\nPerformance optimization guides and profiling tools\nAdvanced deployment patterns and containerization\nScalable architecture design principles\nSystem monitoring and observability frameworks\n\n\n\n\nWeek 9 will focus on final project polish, comprehensive documentation, and presentation preparation."
  },
  {
    "objectID": "course-materials/week8.html#week-8-overview",
    "href": "course-materials/week8.html#week-8-overview",
    "title": "Real-World Application",
    "section": "",
    "text": "This week adapts foundation models for specific tasks using efficient fine-tuning strategies.\n\n\n\nAdapt foundation models for specific tasks\nImplement efficient fine-tuning strategies\nHandle limited labeled data\nEvaluate task performance\n\n\n\n\n\nFull Fine-tuning vs. Parameter-efficient: LoRA and adapter strategies\nFew-shot Learning: Working with limited labeled data\nTask-specific Data: Preparation and augmentation strategies\nMulti-task Learning: Joint training for multiple objectives\nFine-tuning Evaluation: Task-specific performance metrics\n\n\n\n\n\nImplement LoRA and adapter-based fine-tuning\nPrepare task-specific datasets\nCompare full vs. parameter-efficient fine-tuning\nEvaluate few-shot learning capabilities\nOptimize for limited data scenarios\n\n\n\n\nSession 8: Task-Specific Fine-tuning - Efficient fine-tuning strategies and performance optimization\n\n\n\n\nOptimization and feature development work\nSystem testing and validation across scenarios\nDocumentation and user guide creation\nFinal debugging and system refinement\n\n\n\n\nFine-tuned model for chosen application with performance analysis and comparison\n\n\n\n\nComputational Efficiency: Algorithm optimization, parallel processing, memory management\nSystem Architecture: Modular design, component interaction, API development\nUser Experience: Interface improvements, workflow automation, result visualization\nDeployment Readiness: Configuration management, environment portability, monitoring\n\n\n\n\n\nDistributed computing and cloud deployment patterns\nModel serving and API development best practices\nAdvanced visualization and interactive dashboard creation\nSystem monitoring, logging, and error tracking implementation\n\n\n\n\n\nPerformance optimization guides and profiling tools\nAdvanced deployment patterns and containerization\nScalable architecture design principles\nSystem monitoring and observability frameworks\n\n\n\n\nWeek 9 will focus on final project polish, comprehensive documentation, and presentation preparation."
  },
  {
    "objectID": "course-materials/week9.html",
    "href": "course-materials/week9.html",
    "title": "Real-World Application",
    "section": "",
    "text": "This week deploys models for production use, optimizes for inference, and builds user-friendly interfaces.\n\n\n\nDeploy models for production use\nOptimize models for inference\nBuild user-friendly interfaces\nDocument model capabilities\n\n\n\n\n\nModel Optimization: Quantization and optimization for inference\nAPI Development: Building inference APIs with FastAPI\nUser Interface: Creation of interactive web interfaces\nModel Documentation: Model cards and capability documentation\nPerformance Benchmarking: Speed and accuracy analysis\n\n\n\n\n\nOptimize model for efficient inference\nBuild deployment API with documentation\nCreate user interface for model interaction\nWrite comprehensive model cards\nBenchmark performance and document capabilities\n\n\n\n\nDeployable model with documentation: API, user interface, model card, and performance benchmarks\n\n\n\nSession 9: Model Implementation & Deployment - Real-time deployment challenges with live APIs and immediate feedback\n\n\n\nExtended support for: - Final debugging and optimization - Advanced visualization and result analysis - Presentation rehearsals and feedback - Repository organization and documentation\n\n\n\n\nCode review partnerships for quality assurance\nPractice presentations with constructive feedback\nCross-project learning and knowledge sharing\nCollaborative problem-solving for technical challenges\n\n\n\n\n\nProject documentation templates\nPresentation guidelines and rubrics\nCode review checklists\nFinal project submission requirements\n\n\n\n\nWeek 10 will feature final project presentations and discussion of future directions in geospatial foundation models."
  },
  {
    "objectID": "course-materials/week9.html#week-9-overview",
    "href": "course-materials/week9.html#week-9-overview",
    "title": "Real-World Application",
    "section": "",
    "text": "This week deploys models for production use, optimizes for inference, and builds user-friendly interfaces.\n\n\n\nDeploy models for production use\nOptimize models for inference\nBuild user-friendly interfaces\nDocument model capabilities\n\n\n\n\n\nModel Optimization: Quantization and optimization for inference\nAPI Development: Building inference APIs with FastAPI\nUser Interface: Creation of interactive web interfaces\nModel Documentation: Model cards and capability documentation\nPerformance Benchmarking: Speed and accuracy analysis\n\n\n\n\n\nOptimize model for efficient inference\nBuild deployment API with documentation\nCreate user interface for model interaction\nWrite comprehensive model cards\nBenchmark performance and document capabilities\n\n\n\n\nDeployable model with documentation: API, user interface, model card, and performance benchmarks\n\n\n\nSession 9: Model Implementation & Deployment - Real-time deployment challenges with live APIs and immediate feedback\n\n\n\nExtended support for: - Final debugging and optimization - Advanced visualization and result analysis - Presentation rehearsals and feedback - Repository organization and documentation\n\n\n\n\nCode review partnerships for quality assurance\nPractice presentations with constructive feedback\nCross-project learning and knowledge sharing\nCollaborative problem-solving for technical challenges\n\n\n\n\n\nProject documentation templates\nPresentation guidelines and rubrics\nCode review checklists\nFinal project submission requirements\n\n\n\n\nWeek 10 will feature final project presentations and discussion of future directions in geospatial foundation models."
  },
  {
    "objectID": "course-materials/week1.html",
    "href": "course-materials/week1.html",
    "title": "Foundation Building",
    "section": "",
    "text": "This week establishes the foundation for building geospatial foundation models by mastering data preparation and preprocessing pipelines.\n\n\n\nUnderstand geospatial data as foundation model input\nImplement robust data preprocessing pipelines\nHandle missing data (clouds, gaps) effectively\nCreate temporal sequences from satellite imagery\n\n\n\n\n\nGeospatial Tokenization: Convert satellite imagery to model-ready tokens\nMulti-spectral Data: Properties and preprocessing of different bands\nCloud Masking: Strategies for handling missing data\nTemporal Sequences: Building time series from satellite imagery\nData Loaders: Efficient batch processing for training\n\n\n\n\n\nBuild complete geospatial tokenization pipeline\nImplement cloud masking and missing data strategies\nCreate temporal sequence datasets\nOptimize data loading for large-scale training\n\n\n\n\n\nMulti-spectral satellite data properties\nCloud masking algorithms and implementations\nPyTorch data loading best practices\n\n\n\n\nSession 1: Geospatial Data Foundations - Hands-on implementation of geospatial data preprocessing pipeline\n\n\n\nComplete geospatial data pipeline capable of processing satellite imagery for foundation model training\n\n\n\nWeek 2 will implement spatial-temporal attention mechanisms from scratch."
  },
  {
    "objectID": "course-materials/week1.html#week-1-overview",
    "href": "course-materials/week1.html#week-1-overview",
    "title": "Foundation Building",
    "section": "",
    "text": "This week establishes the foundation for building geospatial foundation models by mastering data preparation and preprocessing pipelines.\n\n\n\nUnderstand geospatial data as foundation model input\nImplement robust data preprocessing pipelines\nHandle missing data (clouds, gaps) effectively\nCreate temporal sequences from satellite imagery\n\n\n\n\n\nGeospatial Tokenization: Convert satellite imagery to model-ready tokens\nMulti-spectral Data: Properties and preprocessing of different bands\nCloud Masking: Strategies for handling missing data\nTemporal Sequences: Building time series from satellite imagery\nData Loaders: Efficient batch processing for training\n\n\n\n\n\nBuild complete geospatial tokenization pipeline\nImplement cloud masking and missing data strategies\nCreate temporal sequence datasets\nOptimize data loading for large-scale training\n\n\n\n\n\nMulti-spectral satellite data properties\nCloud masking algorithms and implementations\nPyTorch data loading best practices\n\n\n\n\nSession 1: Geospatial Data Foundations - Hands-on implementation of geospatial data preprocessing pipeline\n\n\n\nComplete geospatial data pipeline capable of processing satellite imagery for foundation model training\n\n\n\nWeek 2 will implement spatial-temporal attention mechanisms from scratch."
  },
  {
    "objectID": "course-materials/week0.html",
    "href": "course-materials/week0.html",
    "title": "Week 0: Getting Started",
    "section": "",
    "text": "Welcome to GEOG 288KC: Geospatial Foundation Models and Applications! This week focuses on getting everyone set up with the computational environment and submitting project applications.\n\n\n\nSet up access to UCSB AI Sandbox\nUnderstand course structure and expectations\nSubmit project application with research interest area\nReview prerequisite knowledge areas\n\n\n\n\n\nComplete UCSB AI Sandbox setup and account access\nSubmit project application describing experience and research interests\nReview course syllabus and deliverable timeline\nSet up development environment (Python, PyTorch, Earth Engine access)\n\n\n\n\n\nUCSB AI Sandbox Documentation\nProject Application Form\nCourse GitHub Repository\n\n\n\n\nProject Application (Due: End of Week 0) - 1-paragraph summary of past experience with remote sensing, geospatial data, and ML - Description of application interest area for Geospatial Foundation Models - Any existing fine-tuning data or project ideas\n\n\n\nWeek 1 will introduce the fundamentals of geospatial foundation models and their applications in remote sensing and environmental monitoring."
  },
  {
    "objectID": "course-materials/week0.html#week-0-overview",
    "href": "course-materials/week0.html#week-0-overview",
    "title": "Week 0: Getting Started",
    "section": "",
    "text": "Welcome to GEOG 288KC: Geospatial Foundation Models and Applications! This week focuses on getting everyone set up with the computational environment and submitting project applications.\n\n\n\nSet up access to UCSB AI Sandbox\nUnderstand course structure and expectations\nSubmit project application with research interest area\nReview prerequisite knowledge areas\n\n\n\n\n\nComplete UCSB AI Sandbox setup and account access\nSubmit project application describing experience and research interests\nReview course syllabus and deliverable timeline\nSet up development environment (Python, PyTorch, Earth Engine access)\n\n\n\n\n\nUCSB AI Sandbox Documentation\nProject Application Form\nCourse GitHub Repository\n\n\n\n\nProject Application (Due: End of Week 0) - 1-paragraph summary of past experience with remote sensing, geospatial data, and ML - Description of application interest area for Geospatial Foundation Models - Any existing fine-tuning data or project ideas\n\n\n\nWeek 1 will introduce the fundamentals of geospatial foundation models and their applications in remote sensing and environmental monitoring."
  },
  {
    "objectID": "course-materials/week2.html",
    "href": "course-materials/week2.html",
    "title": "Foundation Building",
    "section": "",
    "text": "This week implements attention mechanisms from scratch, adapting them specifically for spatial-temporal geospatial relationships.\n\n\n\nImplement self-attention from scratch\nAdapt attention for spatial relationships\nAdd temporal attention for time series\nUnderstand positional encoding for 2D/3D data\n\n\n\n\n\nMulti-head Self-Attention: Implementation from mathematical formulations\n2D Positional Encoding: Spatial position encoding for image patches\nTemporal Encoding: Time series attention for satellite sequences\nCross-attention: Multi-modal data fusion mechanisms\nAttention Visualization: Understanding learned attention patterns\n\n\n\n\n\nImplement multi-head attention from scratch\nBuild 2D positional encoding for spatial patches\nCreate temporal attention for time series data\nVisualize and interpret attention patterns\n\n\n\n\n\nMathematical implementation of attention mechanisms\nPyTorch tensor operations and gradient computation\nAttention pattern visualization\nDebugging dimension mismatches and training issues\n\n\n\n\nSession 2: Spatial-Temporal Attention Mechanisms - Live coding session: Building attention mechanisms with intentional errors and debugging\n\n\n\nCustom attention module for geospatial data with spatial and temporal components\n\n\n\n\nAttention mechanism mathematical foundations\nTransformer architecture deep dive\nSpatial attention for computer vision\n\n\n\n\nWeek 3 will assemble the complete GFM architecture using our custom attention modules."
  },
  {
    "objectID": "course-materials/week2.html#week-2-overview",
    "href": "course-materials/week2.html#week-2-overview",
    "title": "Foundation Building",
    "section": "",
    "text": "This week implements attention mechanisms from scratch, adapting them specifically for spatial-temporal geospatial relationships.\n\n\n\nImplement self-attention from scratch\nAdapt attention for spatial relationships\nAdd temporal attention for time series\nUnderstand positional encoding for 2D/3D data\n\n\n\n\n\nMulti-head Self-Attention: Implementation from mathematical formulations\n2D Positional Encoding: Spatial position encoding for image patches\nTemporal Encoding: Time series attention for satellite sequences\nCross-attention: Multi-modal data fusion mechanisms\nAttention Visualization: Understanding learned attention patterns\n\n\n\n\n\nImplement multi-head attention from scratch\nBuild 2D positional encoding for spatial patches\nCreate temporal attention for time series data\nVisualize and interpret attention patterns\n\n\n\n\n\nMathematical implementation of attention mechanisms\nPyTorch tensor operations and gradient computation\nAttention pattern visualization\nDebugging dimension mismatches and training issues\n\n\n\n\nSession 2: Spatial-Temporal Attention Mechanisms - Live coding session: Building attention mechanisms with intentional errors and debugging\n\n\n\nCustom attention module for geospatial data with spatial and temporal components\n\n\n\n\nAttention mechanism mathematical foundations\nTransformer architecture deep dive\nSpatial attention for computer vision\n\n\n\n\nWeek 3 will assemble the complete GFM architecture using our custom attention modules."
  },
  {
    "objectID": "course-materials/week3.html",
    "href": "course-materials/week3.html",
    "title": "Foundation Building",
    "section": "",
    "text": "This week assembles a complete Vision Transformer architecture adapted for geospatial foundation models, integrating data pipelines and attention mechanisms.\n\n\n\nAssemble complete Vision Transformer architecture\nHandle multi-spectral input processing\nImplement memory-efficient designs\nValidate architecture through testing\n\n\n\n\n\nTransformer Encoder Blocks: Layer normalization and residual connections\nMulti-spectral Input Embedding: Handling different numbers of spectral bands\nArchitecture Testing: Forward pass validation and gradient checking\nMemory Optimization: Efficient attention and activation checkpointing\nModel Scaling: Understanding parameter count and computational requirements\n\n\n\n\n\nBuild complete transformer encoder architecture\nImplement multi-spectral input processing\nTest architecture with sample geospatial data\nOptimize memory usage and computational efficiency\n\n\n\n\n\nPyTorch module composition and inheritance\nMemory profiling and optimization\nArchitecture validation and testing\nUnderstanding model complexity and scaling\n\n\n\n\nSession 3: Complete GFM Architecture - Collaborative architecture decisions: Debating design choices and testing empirically\n\n\n\nWorking GFM architecture (~10M parameters) capable of processing multi-spectral satellite imagery\n\n\n\n\nVision Transformer architecture details\nEfficient transformer implementations\nMemory optimization techniques for large models\n\n\n\n\nWeek 4 begins Stage 2 with masked autoencoder pretraining implementation."
  },
  {
    "objectID": "course-materials/week3.html#week-3-overview",
    "href": "course-materials/week3.html#week-3-overview",
    "title": "Foundation Building",
    "section": "",
    "text": "This week assembles a complete Vision Transformer architecture adapted for geospatial foundation models, integrating data pipelines and attention mechanisms.\n\n\n\nAssemble complete Vision Transformer architecture\nHandle multi-spectral input processing\nImplement memory-efficient designs\nValidate architecture through testing\n\n\n\n\n\nTransformer Encoder Blocks: Layer normalization and residual connections\nMulti-spectral Input Embedding: Handling different numbers of spectral bands\nArchitecture Testing: Forward pass validation and gradient checking\nMemory Optimization: Efficient attention and activation checkpointing\nModel Scaling: Understanding parameter count and computational requirements\n\n\n\n\n\nBuild complete transformer encoder architecture\nImplement multi-spectral input processing\nTest architecture with sample geospatial data\nOptimize memory usage and computational efficiency\n\n\n\n\n\nPyTorch module composition and inheritance\nMemory profiling and optimization\nArchitecture validation and testing\nUnderstanding model complexity and scaling\n\n\n\n\nSession 3: Complete GFM Architecture - Collaborative architecture decisions: Debating design choices and testing empirically\n\n\n\nWorking GFM architecture (~10M parameters) capable of processing multi-spectral satellite imagery\n\n\n\n\nVision Transformer architecture details\nEfficient transformer implementations\nMemory optimization techniques for large models\n\n\n\n\nWeek 4 begins Stage 2 with masked autoencoder pretraining implementation."
  },
  {
    "objectID": "course-materials/week7.html",
    "href": "course-materials/week7.html",
    "title": "System Training",
    "section": "",
    "text": "This week integrates with existing foundation models and compares custom implementations against state-of-the-art.\n\n\n\nLoad and use pretrained foundation models\nCompare custom vs. state-of-the-art models\nUnderstand when to build vs. use existing models\nImplement model ensembling\n\n\n\n\n\nLoading Prithvi and SatMAE: Working with pretrained weights\nArchitecture Compatibility: Adapting existing models to new data\nPerformance Comparison: Custom models vs. state-of-the-art\nTransfer Learning: Strategies for model adaptation\nModel Selection: Criteria for choosing when to build vs. use\n\n\n\n\n\nLoad and configure Prithvi and SatMAE models\nAdapt architectures for compatibility with course data\nCompare performance against custom models\nImplement transfer learning strategies\nCreate model selection framework\n\n\n\n\nSession 7: Integration with Existing Models - Working with Prithvi, SatMAE, and performance comparison\n\n\n\n\nIndependent implementation with instructor feedback\nSmall-group collaboration and knowledge sharing\nTroubleshooting sessions and milestone tracking\n\n\n\n\nIntegrated system using multiple models with performance comparison and model selection guidelines\n\n\n\n\nDevelopment Best Practices: Code organization, testing frameworks, documentation\nPerformance Monitoring: Computational efficiency, resource utilization, bottleneck identification\nVersion Control: Branching strategies, collaborative workflows, milestone tracking\nEnvironment Management: Reproducible setups, dependency management, deployment preparation\n\n\n\n\n\nStructured code review sessions with feedback protocols\nKnowledge sharing presentations on technical solutions\nCollaborative debugging and problem-solving workshops\nCross-project learning and technique exchange\n\n\n\n\n\nAdvanced development pattern guides\nModel optimization and debugging tools\nPerformance profiling and monitoring utilities\nCollaborative development workflows\n\n\n\n\nWeek 8 will focus on project refinement, advanced features, and scalability improvements."
  },
  {
    "objectID": "course-materials/week7.html#week-7-overview",
    "href": "course-materials/week7.html#week-7-overview",
    "title": "System Training",
    "section": "",
    "text": "This week integrates with existing foundation models and compares custom implementations against state-of-the-art.\n\n\n\nLoad and use pretrained foundation models\nCompare custom vs. state-of-the-art models\nUnderstand when to build vs. use existing models\nImplement model ensembling\n\n\n\n\n\nLoading Prithvi and SatMAE: Working with pretrained weights\nArchitecture Compatibility: Adapting existing models to new data\nPerformance Comparison: Custom models vs. state-of-the-art\nTransfer Learning: Strategies for model adaptation\nModel Selection: Criteria for choosing when to build vs. use\n\n\n\n\n\nLoad and configure Prithvi and SatMAE models\nAdapt architectures for compatibility with course data\nCompare performance against custom models\nImplement transfer learning strategies\nCreate model selection framework\n\n\n\n\nSession 7: Integration with Existing Models - Working with Prithvi, SatMAE, and performance comparison\n\n\n\n\nIndependent implementation with instructor feedback\nSmall-group collaboration and knowledge sharing\nTroubleshooting sessions and milestone tracking\n\n\n\n\nIntegrated system using multiple models with performance comparison and model selection guidelines\n\n\n\n\nDevelopment Best Practices: Code organization, testing frameworks, documentation\nPerformance Monitoring: Computational efficiency, resource utilization, bottleneck identification\nVersion Control: Branching strategies, collaborative workflows, milestone tracking\nEnvironment Management: Reproducible setups, dependency management, deployment preparation\n\n\n\n\n\nStructured code review sessions with feedback protocols\nKnowledge sharing presentations on technical solutions\nCollaborative debugging and problem-solving workshops\nCross-project learning and technique exchange\n\n\n\n\n\nAdvanced development pattern guides\nModel optimization and debugging tools\nPerformance profiling and monitoring utilities\nCollaborative development workflows\n\n\n\n\nWeek 8 will focus on project refinement, advanced features, and scalability improvements."
  },
  {
    "objectID": "course-materials/week6.html",
    "href": "course-materials/week6.html",
    "title": "System Training",
    "section": "",
    "text": "This week evaluates representation quality, assesses reconstruction performance, and compares against baselines.\n\n\n\nEvaluate representation quality\nAssess reconstruction performance\nCompare against baselines\nUnderstand learned features\n\n\n\n\n\nEmbedding Visualization: t-SNE, UMAP for learned representations\nReconstruction Quality: Assessment metrics and visual analysis\nLinear Probing: Evaluation of learned features for downstream tasks\nFeature Interpretation: Understanding what the model has learned\nAblation Studies: Component importance analysis\n\n\n\n\n\nGenerate and visualize learned embeddings\nEvaluate reconstruction quality on test data\nImplement linear probing for classification tasks\nAnalyze learned attention patterns and features\nCompare against random initialization baselines\n\n\n\n\nSession 6: Model Evaluation & Analysis - Comprehensive evaluation with embedding visualization and performance analysis\n\n\n\nComprehensive evaluation report with embedding visualizations, reconstruction analysis, and baseline comparisons\n\n\n\n\nProject repository structure and best practices\nReproducible environment setup (conda, Docker, requirements)\nData management and version control strategies\nComputational resource allocation and optimization\n\n\n\n\n\nProject proposal templates and examples\nRepository structure guidelines\nUCSB AI Sandbox resource allocation\nTechnical consultation scheduling system\n\n\n\n\nWeek 7 will focus on intensive development with regular progress check-ins and technical workshops."
  },
  {
    "objectID": "course-materials/week6.html#week-6-overview",
    "href": "course-materials/week6.html#week-6-overview",
    "title": "System Training",
    "section": "",
    "text": "This week evaluates representation quality, assesses reconstruction performance, and compares against baselines.\n\n\n\nEvaluate representation quality\nAssess reconstruction performance\nCompare against baselines\nUnderstand learned features\n\n\n\n\n\nEmbedding Visualization: t-SNE, UMAP for learned representations\nReconstruction Quality: Assessment metrics and visual analysis\nLinear Probing: Evaluation of learned features for downstream tasks\nFeature Interpretation: Understanding what the model has learned\nAblation Studies: Component importance analysis\n\n\n\n\n\nGenerate and visualize learned embeddings\nEvaluate reconstruction quality on test data\nImplement linear probing for classification tasks\nAnalyze learned attention patterns and features\nCompare against random initialization baselines\n\n\n\n\nSession 6: Model Evaluation & Analysis - Comprehensive evaluation with embedding visualization and performance analysis\n\n\n\nComprehensive evaluation report with embedding visualizations, reconstruction analysis, and baseline comparisons\n\n\n\n\nProject repository structure and best practices\nReproducible environment setup (conda, Docker, requirements)\nData management and version control strategies\nComputational resource allocation and optimization\n\n\n\n\n\nProject proposal templates and examples\nRepository structure guidelines\nUCSB AI Sandbox resource allocation\nTechnical consultation scheduling system\n\n\n\n\nWeek 7 will focus on intensive development with regular progress check-ins and technical workshops."
  },
  {
    "objectID": "course-materials/week4.html",
    "href": "course-materials/week4.html",
    "title": "System Training",
    "section": "",
    "text": "This week implements masked autoencoder pretraining for geospatial foundation models, setting up the complete training pipeline.\n\n\n\nImplement masked autoencoder objective\nSet up distributed training pipeline\nMonitor training progress effectively\nHandle large-scale geospatial datasets\n\n\n\n\n\nMasked Patch Reconstruction: Prithvi-style self-supervised learning\nTraining Data Preparation: Augmentation and batch creation\nLoss Functions: Reconstruction loss for masked patches\nDistributed Training: Multi-GPU setup and synchronization\nMonitoring and Logging: Training metrics and visualization\n\n\n\n\n\nImplement masked autoencoder training objective\nSet up distributed training infrastructure\nCreate training data augmentation pipeline\nBuild monitoring and logging system\n\n\n\n\n\nSelf-supervised learning implementation\nDistributed training with PyTorch Lightning\nTraining monitoring and debugging\nLarge-scale data handling\n\n\n\n\nSession 4: Pretraining Implementation - Launch first pretraining run with real satellite data\n\n\n\nActive pretraining pipeline with monitoring and checkpointing\n\n\n\n\nMasked Autoencoder (MAE) paper and implementation\nPrithvi training methodology\nDistributed training best practices\n\n\n\n\nWeek 5 will optimize the training loop for stability and efficiency."
  },
  {
    "objectID": "course-materials/week4.html#week-4-overview",
    "href": "course-materials/week4.html#week-4-overview",
    "title": "System Training",
    "section": "",
    "text": "This week implements masked autoencoder pretraining for geospatial foundation models, setting up the complete training pipeline.\n\n\n\nImplement masked autoencoder objective\nSet up distributed training pipeline\nMonitor training progress effectively\nHandle large-scale geospatial datasets\n\n\n\n\n\nMasked Patch Reconstruction: Prithvi-style self-supervised learning\nTraining Data Preparation: Augmentation and batch creation\nLoss Functions: Reconstruction loss for masked patches\nDistributed Training: Multi-GPU setup and synchronization\nMonitoring and Logging: Training metrics and visualization\n\n\n\n\n\nImplement masked autoencoder training objective\nSet up distributed training infrastructure\nCreate training data augmentation pipeline\nBuild monitoring and logging system\n\n\n\n\n\nSelf-supervised learning implementation\nDistributed training with PyTorch Lightning\nTraining monitoring and debugging\nLarge-scale data handling\n\n\n\n\nSession 4: Pretraining Implementation - Launch first pretraining run with real satellite data\n\n\n\nActive pretraining pipeline with monitoring and checkpointing\n\n\n\n\nMasked Autoencoder (MAE) paper and implementation\nPrithvi training methodology\nDistributed training best practices\n\n\n\n\nWeek 5 will optimize the training loop for stability and efficiency."
  },
  {
    "objectID": "course-materials/week5.html",
    "href": "course-materials/week5.html",
    "title": "System Training",
    "section": "",
    "text": "This week optimizes training for stability and efficiency, handling geospatial-specific training challenges.\n\n\n\nOptimize training for stability and efficiency\nHandle geospatial-specific training challenges\nImplement advanced optimization techniques\nDebug training issues\n\n\n\n\n\nLearning Rate Scheduling: Warm-up, cosine annealing, adaptive strategies\nGradient Management: Clipping, accumulation, normalization\nMixed Precision Training: Automatic mixed precision (AMP) implementation\nMissing Data Handling: Training with cloud-contaminated patches\nTraining Stability: Convergence analysis and debugging\n\n\n\n\n\nImplement advanced learning rate schedulers\nAdd gradient clipping and accumulation\nEnable mixed precision training\nDebug training instabilities and convergence issues\n\n\n\n\n\nAdvanced PyTorch optimization\nTraining stability analysis\nPerformance profiling and optimization\nSystematic debugging of training issues\n\n\n\n\nSession 5: Training Loop Optimization - Performance archaeology: Investigating training curves and optimization dynamics\n\n\n\nOptimized training loop with monitoring and stability guarantees\n\n\n\n\nTraining stability best practices\nMixed precision training guides\nOptimization theory for deep learning\n\n\n\n\nWeek 6 will evaluate model performance and analyze learned representations."
  },
  {
    "objectID": "course-materials/week5.html#week-5-overview",
    "href": "course-materials/week5.html#week-5-overview",
    "title": "System Training",
    "section": "",
    "text": "This week optimizes training for stability and efficiency, handling geospatial-specific training challenges.\n\n\n\nOptimize training for stability and efficiency\nHandle geospatial-specific training challenges\nImplement advanced optimization techniques\nDebug training issues\n\n\n\n\n\nLearning Rate Scheduling: Warm-up, cosine annealing, adaptive strategies\nGradient Management: Clipping, accumulation, normalization\nMixed Precision Training: Automatic mixed precision (AMP) implementation\nMissing Data Handling: Training with cloud-contaminated patches\nTraining Stability: Convergence analysis and debugging\n\n\n\n\n\nImplement advanced learning rate schedulers\nAdd gradient clipping and accumulation\nEnable mixed precision training\nDebug training instabilities and convergence issues\n\n\n\n\n\nAdvanced PyTorch optimization\nTraining stability analysis\nPerformance profiling and optimization\nSystematic debugging of training issues\n\n\n\n\nSession 5: Training Loop Optimization - Performance archaeology: Investigating training curves and optimization dynamics\n\n\n\nOptimized training loop with monitoring and stability guarantees\n\n\n\n\nTraining stability best practices\nMixed precision training guides\nOptimization theory for deep learning\n\n\n\n\nWeek 6 will evaluate model performance and analyze learned representations."
  },
  {
    "objectID": "course-materials/week10.html",
    "href": "course-materials/week10.html",
    "title": "Real-World Application",
    "section": "",
    "text": "This week presents complete model pipelines, synthesizes course learnings, and identifies future research directions.\n\n\n\nPresent complete model pipeline\nSynthesize course learnings\nIdentify future research directions\nPlan continued development\n\n\n\n\n\nFinal Project Presentations: Complete foundation model pipeline demonstrations\nPerformance Analysis: Comparison with state-of-the-art models\nScaling Strategies: Discussion of computational and data requirements\nFuture Work: Identification of research and development opportunities\nCourse Reflection: Synthesis of build-first learning approach\n\n\n\n\nComplete foundation model pipeline with: - Working architecture built from scratch - Trained model with evaluation results - Deployed system with API and interface - Comparison with existing foundation models - Documentation and presentation materials\n\n\n\nSession 10: Project Presentations & Synthesis - Present complete foundation model systems and synthesize course learnings\n\n\n\n\nPresent complete foundation model systems\nDemonstrate end-to-end pipelines with live data\nCompare performance against state-of-the-art\nDiscuss scaling and future development\nReflect on course transformation from consumers to creators\n\n\n\n\n\nEmerging Trends: Latest developments in foundation model architectures\nApplication Domains: Unexplored areas and promising applications\nTechnical Challenges: Scalability, interpretability, robustness\nSocietal Impact: Environmental monitoring, disaster response, climate science\nFuture Research: Open problems, collaboration opportunities\n\n\n\n\nHugging Face/GitHub Submission: - Students may optionally submit polished projects to public repositories - Opportunity for broader visibility and community engagement - Instructor support for preparing submission-quality documentation\nConference/Workshop Submissions: - Guidance on adapting projects for academic conferences - Identification of relevant venues and submission opportunities - Support for preparing extended abstracts or full papers\n\n\n\n\nProject Repository: Complete, documented codebase with examples\nFinal Report: Comprehensive technical document (5-10 pages)\nPresentation Materials: Slides and any supporting materials\nPeer Evaluations: Constructive feedback on all peer presentations\n\n\n\n\n\nIndividual reflection essays on key learnings and growth\nCourse feedback and suggestions for future iterations\nIdentification of personal next steps and continued learning goals\n\n\n\n\n\nPresentation templates and guidelines\nProject submission checklists\nConference and journal venue lists\nNetworking and collaboration opportunities\n\n\n\n\nRecognition of outstanding projects and contributions to course community!"
  },
  {
    "objectID": "course-materials/week10.html#week-10-overview",
    "href": "course-materials/week10.html#week-10-overview",
    "title": "Real-World Application",
    "section": "",
    "text": "This week presents complete model pipelines, synthesizes course learnings, and identifies future research directions.\n\n\n\nPresent complete model pipeline\nSynthesize course learnings\nIdentify future research directions\nPlan continued development\n\n\n\n\n\nFinal Project Presentations: Complete foundation model pipeline demonstrations\nPerformance Analysis: Comparison with state-of-the-art models\nScaling Strategies: Discussion of computational and data requirements\nFuture Work: Identification of research and development opportunities\nCourse Reflection: Synthesis of build-first learning approach\n\n\n\n\nComplete foundation model pipeline with: - Working architecture built from scratch - Trained model with evaluation results - Deployed system with API and interface - Comparison with existing foundation models - Documentation and presentation materials\n\n\n\nSession 10: Project Presentations & Synthesis - Present complete foundation model systems and synthesize course learnings\n\n\n\n\nPresent complete foundation model systems\nDemonstrate end-to-end pipelines with live data\nCompare performance against state-of-the-art\nDiscuss scaling and future development\nReflect on course transformation from consumers to creators\n\n\n\n\n\nEmerging Trends: Latest developments in foundation model architectures\nApplication Domains: Unexplored areas and promising applications\nTechnical Challenges: Scalability, interpretability, robustness\nSocietal Impact: Environmental monitoring, disaster response, climate science\nFuture Research: Open problems, collaboration opportunities\n\n\n\n\nHugging Face/GitHub Submission: - Students may optionally submit polished projects to public repositories - Opportunity for broader visibility and community engagement - Instructor support for preparing submission-quality documentation\nConference/Workshop Submissions: - Guidance on adapting projects for academic conferences - Identification of relevant venues and submission opportunities - Support for preparing extended abstracts or full papers\n\n\n\n\nProject Repository: Complete, documented codebase with examples\nFinal Report: Comprehensive technical document (5-10 pages)\nPresentation Materials: Slides and any supporting materials\nPeer Evaluations: Constructive feedback on all peer presentations\n\n\n\n\n\nIndividual reflection essays on key learnings and growth\nCourse feedback and suggestions for future iterations\nIdentification of personal next steps and continued learning goals\n\n\n\n\n\nPresentation templates and guidelines\nProject submission checklists\nConference and journal venue lists\nNetworking and collaboration opportunities\n\n\n\n\nRecognition of outstanding projects and contributions to course community!"
  }
]